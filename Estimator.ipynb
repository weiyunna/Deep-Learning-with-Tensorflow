{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Estimator",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/weiyunna/Deep-Learning-with-Tensorflow/blob/master/Estimator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "zCV17bqogLJ9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Estimators"
      ]
    },
    {
      "metadata": {
        "id": "v6qxNxZqgv9D",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This document introduces tf.estimator—a high-level TensorFlow API that greatly **simplifies machine learning programming**. Estimators encapsulate the following actions:\n",
        "\n",
        "* training\n",
        "* evaluation\n",
        "* prediction\n",
        "* export for serving\n",
        "\n",
        "You may either use the pre-made Estimators we provide or write your own custom Estimators. All Estimators—whether** pre-made or custom**—are classes based on the **tf.estimator.Estimator** class.\n",
        "\n",
        "For a quick example try **Estimator tutorials**. To see each sub-topic in depth, see the **Estimator guides**. For an overview of **the API design**, see our white paper here."
      ]
    },
    {
      "metadata": {
        "id": "9HQSinLtiwCq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Estimators are TensorFlow's most scalable and production-oriented model type"
      ]
    },
    {
      "metadata": {
        "id": "a_xCzoGKhUd7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Advantages of Estimators"
      ]
    },
    {
      "metadata": {
        "id": "rHj_RXvihReD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Estimators provide the following benefits:\n",
        "\n",
        "* You can run Estimator-based models on a local host or on a distributed multi-server environment without changing your model. Furthermore, you can run Estimator-based models on CPUs, GPUs, or TPUs without recoding your model.\n",
        "\n",
        "\n",
        "* Estimators simplify sharing implementations between model developers.\n",
        "* You can develop a state of the art model with high-level intuitive code. In short, it is generally much easier to create models with Estimators than with the low-level TensorFlow APIs.\n",
        "* Estimators are themselves built on tf.keras.layers, which simplifies customization.\n",
        "* Estimators build the graph for you.\n",
        "* Estimators provide a safe distributed training loop that controls how and when to:\n",
        "\n",
        "  * build the graph\n",
        "  * initialize variables\n",
        "  * load data\n",
        "  * handle exceptions\n",
        "  * create checkpoint files and recover from failures\n",
        "  * save summaries for TensorBoard\n",
        "\n",
        "When writing an application with Estimators, you must separate the data input pipeline from the model. This separation simplifies experiments with different data sets."
      ]
    },
    {
      "metadata": {
        "id": "eNwbqOM-iFzr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Pre-made Estimators"
      ]
    },
    {
      "metadata": {
        "id": "QDgjznFAiD4T",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Pre-made Estimators enable you to work at a much higher conceptual level than the base TensorFlow APIs. \n",
        "\n",
        "You no longer have to worry about creating the **computational graph or sessions **since Estimators handle all the \"plumbing\" for you. \n",
        "\n",
        "That is, pre-made Estimators create and manage tf.Graph and tf.Session objects for you. \n",
        "\n",
        "Furthermore, pre-made Estimators let you experiment with different model architectures by making only minimal code changes.\n",
        "\n",
        "**tf.estimator.DNNClassifier**, for example, is a pre-made Estimator class that trains classification models based on dense, feed-forward neural networks."
      ]
    },
    {
      "metadata": {
        "id": "Lkx1Mqq5jKtj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Structure of a pre-made Estimators program"
      ]
    },
    {
      "metadata": {
        "id": "IgtjGSx5jNwD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "A TensorFlow program relying on a pre-made Estimator typically consists of the following four steps:\n",
        "\n",
        "* Write one or more dataset importing functions\n",
        "* Define the feature columns\n",
        "* Instantiate the relevant pre-made Estimator\n",
        "* Call a training, evaluation, or inference method"
      ]
    },
    {
      "metadata": {
        "id": "dvR5B033jpxL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Write one or more dataset importing functions"
      ]
    },
    {
      "metadata": {
        "id": "HwEJLF9Ej0Fq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "For example, you might create one function to import the training set and another function to import the test set. Each dataset importing function must return two objects:\n",
        "\n",
        "* a dictionary in which the keys are feature names and the values are Tensors (or SparseTensors) containing the corresponding **feature** data\n",
        "* a Tensor containing one or more **labels**\n",
        "\n",
        "For example, the following code illustrates the basic skeleton for an input function:"
      ]
    },
    {
      "metadata": {
        "id": "DXL0IIQvgM_d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def input_fn(dataset):\n",
        "   ...  # manipulate dataset, extracting the feature dict and the label\n",
        "   return feature_dict, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZGYO-fs7kFwy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Define the feature columns"
      ]
    },
    {
      "metadata": {
        "id": "xYqrF26vkYtr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " Each` tf.feature_column` identifies a **feature name**, **its type**, and any input **pre-processing**. For example, the following snippet creates three feature columns that hold integer or floating-point data. The first two feature columns simply identify the feature's name and type. The third feature column also **specifies a lambda the program will invoke to scale the raw data:**"
      ]
    },
    {
      "metadata": {
        "id": "Qo1H9audkLnQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Define three numeric feature columns.\n",
        "population = tf.feature_column.numeric_column('population')\n",
        "crime_rate = tf.feature_column.numeric_column('crime_rate')\n",
        "median_education = tf.feature_column.numeric_column('median_education',\n",
        "                    normalizer_fn=lambda x: x - global_education_mean)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4mukq8H5kzeB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Instantiate the relevant pre-made Estimator"
      ]
    },
    {
      "metadata": {
        "id": "KgFAtwXfk3YZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "For example, here's a sample instantiation of a pre-made Estimator named **LinearClassifier**:"
      ]
    },
    {
      "metadata": {
        "id": "L1IwCuzYk1la",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Instantiate an estimator, passing the feature columns.\n",
        "estimator = tf.estimator.LinearClassifier(\n",
        "    feature_columns=[population, crime_rate, median_education])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "REXm8uJPlGlS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Call a training, evaluation, or inference method"
      ]
    },
    {
      "metadata": {
        "id": "0ZrfiT6zlKJ6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "For example, all Estimators provide a train method, which trains a model."
      ]
    },
    {
      "metadata": {
        "id": "hflHewcDk9cr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# `input_fn` is the function created in Step 1\n",
        "estimator.train(input_fn=my_training_set, steps=2000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ktLy02yKlU8S",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Benefits of pre-made Estimators"
      ]
    },
    {
      "metadata": {
        "id": "O-SeYWoelYVD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Pre-made Estimators encode best practices, providing the following benefits:\n",
        "\n",
        "* Best practices for determining where different parts of the computational graph should run, implementing strategies on a single machine or on a cluster.\n",
        "* Best practices for event (summary) writing and universally useful summaries.\n",
        "\n",
        "If you don't use pre-made Estimators, you must implement the preceding features yourself."
      ]
    },
    {
      "metadata": {
        "id": "bvmhYvyymBrj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Custom Estimators"
      ]
    },
    {
      "metadata": {
        "id": "JJRe23qmmFs6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The heart of every Estimator—whether pre-made or custom**—is its model function, which is a method that builds graphs for training, evaluation, and prediction**. When you are using a pre-made Estimator, someone else has already implemented the model function. When relying on a custom Estimator, you must write the model function yourself. A companion document explains how to write the model function."
      ]
    },
    {
      "metadata": {
        "id": "AJfoPWl4mS7r",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Recommended Workflow"
      ]
    },
    {
      "metadata": {
        "id": "ijeVsKUemZAL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We recommend the following workflow:\n",
        "\n",
        "* Assuming a suitable pre-made Estimator exists, use it to build your first model and use its results to establish a baseline.\n",
        "* Build and test your overall pipeline, including the integrity and reliability of your data with this pre-made Estimator.\n",
        "* If suitable alternative pre-made Estimators are available, run experiments to determine which pre-made Estimator produces the best results.\n",
        "* Possibly, further improve your model by building your own custom Estimator."
      ]
    },
    {
      "metadata": {
        "id": "tjEHkaAdmzj7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Creating Estimators from Keras models"
      ]
    },
    {
      "metadata": {
        "id": "ytngk_4tm33T",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "You can convert existing Keras models to Estimators. Doing so enables your Keras model to access Estimator's strengths, such as **distributed training**. Call **tf.keras.estimator.model_to_estimator** as in the following sample:"
      ]
    },
    {
      "metadata": {
        "id": "cwfL8HCelXpw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Instantiate a Keras inception v3 model.\n",
        "keras_inception_v3 = tf.keras.applications.inception_v3.InceptionV3(weights=None)\n",
        "\n",
        "# Compile model with the optimizer, loss, and metrics you'd like to train with.\n",
        "keras_inception_v3.compile(optimizer=tf.keras.optimizers.SGD(lr=0.0001, momentum=0.9),\n",
        "                          loss='categorical_crossentropy',\n",
        "                          metric='accuracy')\n",
        "                          \n",
        "# Create an Estimator from the compiled Keras model. Note the initial model\n",
        "# state of the keras model is preserved in the created Estimator.\n",
        "est_inception_v3 = tf.keras.estimator.model_to_estimator(keras_model=keras_inception_v3)\n",
        "\n",
        "# Treat the derived Estimator as you would with any other Estimator.\n",
        "# First, recover the input name(s) of Keras model, so we can use them as the\n",
        "# feature column name(s) of the Estimator input function:\n",
        "keras_inception_v3.input_names  # print out: ['input_1']\n",
        "\n",
        "# Once we have the input name(s), we can create the input function, for example,\n",
        "# for input(s) in the format of numpy ndarray:\n",
        "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
        "    x={\"input_1\": train_data},\n",
        "    y=train_labels,\n",
        "    num_epochs=1,\n",
        "    shuffle=False)\n",
        "    \n",
        "# To train, we call Estimator's train function:\n",
        "est_inception_v3.train(input_fn=train_input_fn, steps=2000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lTRMcYKwnwNT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Note that the names of feature columns and labels of a keras estimator come from the corresponding compiled keras model.\n",
        "\n",
        "For example, the input key names for **train_input_fn **above can be obtained from **keras_inception_v3.input_names**, and similarly, the predicted output names can be obtained from **keras_inception_v3.output_names**."
      ]
    },
    {
      "metadata": {
        "id": "UaPu-Twtn8vL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}