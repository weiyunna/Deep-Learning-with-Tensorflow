{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transfer Learning with ResNet50",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/weiyunna/Deep-Learning-with-Tensorflow/blob/master/Transfer_Learning_with_ResNet50.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "HclSzeGYiELl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Transfer Learning with ResNet 50\n",
        "\n",
        "This kernel is intended to be a tutorial on Keras around image files handling for Transfer Learning using pre-trained weights from ResNet50 convnet.\n",
        "\n",
        "Though loading all train & test images resized (224 x 224 x 3) in memory would have incurred ~4.9GB of memory, the plan was to batch source image data during the training, validation & testing pipeline. Keras ImageDataGenerator supports batch sourcing image data for all training, validation and testing. Actually, it is quite clean and easy to use Keras ImageDataGenerator except few limitations (listed at the end).\n",
        "\n",
        "Keras ImageDataGenerator expects labeled training images to be available in certain folder heirarchy, 'train' data was manually split into 10k for training & 2.5k for validation and re-arranged into the desired folder hierarchy. Even 'test' images had to rearranged due to a known issue in flow_from_directory."
      ]
    },
    {
      "metadata": {
        "id": "W1eMk-F7iOqv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline \n",
        "\n",
        "import cv2\n",
        "\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WAF5Ahnzk2rw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e9c2ab74-b2a7-4104-e2c5-14b926851675"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.python.keras.applications import ResNet50\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Dense\n",
        "\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.13.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "dCKdqhIRUG5U"
      },
      "cell_type": "markdown",
      "source": [
        "## Connect with the Google Drive"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "77308c8d-603b-497c-a0ab-11746294c8e3",
        "id": "adlBYK_SUG5Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.listdir(\".\"))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['The Hello World of Neural Network', 'Week1', 'Week1-Exercise1', 'Week2-Computer Vision on Fashion MINST', 'MINST Digits Recognition', 'Improving Computer Vision Accuracy using Convolutions', 'CNN_Filters and Pools', 'Horse or Human - Image Classification', 'Face Recognition', 'An End-to-End-Data-Science-Framework', 'Azure-aml-real-time-ai', 'Introduction to Pandas', 'First-Steps-With-Tensorflow', 'Introduction to Keras', 'Introduction to Neural Nets', 'Introduction to Matplotlib', 'Introduction to Bokeh', 'Images', 'resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5', 'Transfer Learning with ResNet50']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "ebd50471-c604-4b72-9d58-94d114430a9b",
        "id": "riQrFpsqUG5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Authorization\n",
        "\n",
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E: Package 'python-software-properties' has no installation candidate\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "GieZa7iKUG5f",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "jbftSjSeUG5j",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# Mount drive to \"drive/\" folder\n",
        "\n",
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "f9f7960b-eebf-463b-a275-b172dad34ef4",
        "id": "5h99YX0jUG5l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "print(os.listdir(\"drive/Colab Notebooks/\"))\n",
        "os.chdir(\"drive/Colab Notebooks/\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['The Hello World of Neural Network', 'Week1', 'Week1-Exercise1', 'Week2-Computer Vision on Fashion MINST', 'MINST Digits Recognition', 'Improving Computer Vision Accuracy using Convolutions', 'CNN_Filters and Pools', 'Horse or Human - Image Classification', 'Face Recognition', 'An End-to-End-Data-Science-Framework', 'Azure-aml-real-time-ai', 'Introduction to Pandas', 'First-Steps-With-Tensorflow', 'Introduction to Keras', 'Introduction to Neural Nets', 'Introduction to Matplotlib', 'Introduction to Bokeh', 'Transfer Learning with ResNet50']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "c38df1bf-2f3d-4128-df99-da55c4d8e97f",
        "id": "sANcdND-UG5p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "print(os.listdir(\".\"))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Introduction to Pandas', 'First-Steps-With-Tensorflow', 'Azure-aml-real-time-ai', 'Week2-Computer Vision on Fashion MINST', 'CNN_Filters and Pools', 'Week1', 'An End-to-End-Data-Science-Framework', 'Transfer Learning with ResNet50', 'Introduction to Neural Nets', 'Week1-Exercise1', 'Improving Computer Vision Accuracy using Convolutions', 'Images', 'The Hello World of Neural Network', 'MINST Digits Recognition', 'Face Recognition', 'Introduction to Bokeh', 'Introduction to Keras', 'resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5', 'Introduction to Matplotlib', 'Horse or Human - Image Classification']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5GZ_kJrSUQa2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Define the Global Constants"
      ]
    },
    {
      "metadata": {
        "id": "os62ZaQLjPo7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Fixed for our Cats & Dogs classes\n",
        "NUM_CLASSES = 2\n",
        "\n",
        "# Fixed for Cats & Dogs color images\n",
        "CHANNELS = 3\n",
        "\n",
        "IMAGE_RESIZE = 224\n",
        "RESNET50_POOLING_AVERAGE = 'avg'\n",
        "DENSE_LAYER_ACTIVATION = 'softmax'\n",
        "OBJECTIVE_FUNCTION = 'categorical_crossentropy'\n",
        "\n",
        "# Common accuracy metric for all outputs, but can use different metrics for different output\n",
        "LOSS_METRICS = ['accuracy']\n",
        "\n",
        "# EARLY_STOP_PATIENCE must be < NUM_EPOCHS\n",
        "NUM_EPOCHS = 10\n",
        "EARLY_STOP_PATIENCE = 3\n",
        "\n",
        "# These steps value should be proper FACTOR of no.-of-images in train & valid folders respectively\n",
        "# Training images processed in each step would be no.-of-train-images / STEPS_PER_EPOCH_TRAINING\n",
        "STEPS_PER_EPOCH_TRAINING = 10\n",
        "STEPS_PER_EPOCH_VALIDATION = 10\n",
        "\n",
        "# These steps value should be proper FACTOR of no.-of-images in train & valid folders respectively\n",
        "# NOTE that these BATCH* are for Keras ImageDataGenerator batching to fill epoch step input\n",
        "BATCH_SIZE_TRAINING = 100\n",
        "BATCH_SIZE_VALIDATION = 100\n",
        "\n",
        "# Using 1 to easily manage mapping between test_generator & prediction for submission preparation\n",
        "BATCH_SIZE_TESTING = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZBGFDJOilsA1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## ResNet50\n",
        "\n",
        "* Notice that resnet50 folder has 2 pre-trained weights files... xyz_tf_kernels.h5 & xyz_tf_kernels_NOTOP.h5\n",
        "\n",
        "* The xyz_tf_kernels.h5 weights is useful for pure prediction of test image and this prediction will rely completely on ResNet50 pre-trained weights, i.e., it does not expected any training from our side\n",
        "\n",
        "* Out intention in this kernel is Transfer Learning by using ResNet50 pre-trained weights except its TOP layer, i.e., the xyz_tf_kernels_NOTOP.h5 weights... Use this weights as initial weight for training new layer using train images"
      ]
    },
    {
      "metadata": {
        "id": "dRn9PW2zT2J8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "outputId": "e056bd13-0c17-445c-987b-22e7596714e2"
      },
      "cell_type": "code",
      "source": [
        "print(os.listdir(\"drive/Colab Notebooks/\"))\n",
        "os.chdir(\"drive/Colab Notebooks/\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-a05a056fa00a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"drive/Colab Notebooks/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"drive/Colab Notebooks/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'drive/Colab Notebooks/'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "D0IH_ew4mAe4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "resnet_weights_path = '/Colab Notebooks/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dpb-ZIPrmr6r",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Define Our Transfer Learning Network Model Consisting of 2 Layers\n",
        "Here, we are preparing specification or blueprint of the TensorFlow DAG (directed acyclcic graph) for just the MODEL part."
      ]
    },
    {
      "metadata": {
        "id": "U92NqiJ3mmB1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 602
        },
        "outputId": "368a90da-8a8e-40be-8434-ace31623279e"
      },
      "cell_type": "code",
      "source": [
        "#Still not talking about our train/test data or any pre-processing.\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# 1st layer as the lumpsum weights from resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "# NOTE that this layer will be set below as NOT TRAINABLE, i.e., use it as is\n",
        "model.add(ResNet50(include_top = False, pooling = RESNET50_POOLING_AVERAGE, weights = resnet_weights_path))\n",
        "\n",
        "# 2nd layer as Dense for 2-class classification, i.e., dog or cat using SoftMax activation\n",
        "model.add(Dense(NUM_CLASSES, activation = DENSE_LAYER_ACTIVATION))\n",
        "\n",
        "# Say not to train first layer (ResNet) model as it is already trained\n",
        "model.layers[0].trainable = False"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-f58b67ccd3f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# 1st layer as the lumpsum weights from resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# NOTE that this layer will be set below as NOT TRAINABLE, i.e., use it as is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResNet50\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude_top\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpooling\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRESNET50_POOLING_AVERAGE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresnet_weights_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# 2nd layer as Dense for 2-class classification, i.e., dog or cat using SoftMax activation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/applications/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'models'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'utils'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbase_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/applications/resnet50.py\u001b[0m in \u001b[0;36mResNet50\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mkeras_modules_injection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mResNet50\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mresnet50\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResNet50\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py\u001b[0m in \u001b[0;36mResNet50\u001b[0;34m(include_top, weights, input_tensor, input_shape, pooling, classes, **kwargs)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'imagenet'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         raise ValueError('The `weights` argument should be either '\n\u001b[0m\u001b[1;32m    197\u001b[0m                          \u001b[0;34m'`None` (random initialization), `imagenet` '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                          \u001b[0;34m'(pre-training on ImageNet), '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The `weights` argument should be either `None` (random initialization), `imagenet` (pre-training on ImageNet), or the path to the weights file to be loaded."
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "IzSButbPm9Te",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "4ced00eb-c559-4048-a07d-4487b6d1b082"
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "resnet50 (Model)             (None, 2048)              23587712  \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 4098      \n",
            "=================================================================\n",
            "Total params: 23,591,810\n",
            "Trainable params: 4,098\n",
            "Non-trainable params: 23,587,712\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FfEkQyZk17ro",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Compile Our Transfer Learning Model"
      ]
    },
    {
      "metadata": {
        "id": "7N0KOs0v11eg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.python.keras import optimizers\n",
        "\n",
        "sgd = optimizers.SGD(lr = 0.01, decay = 1e-6, momentum = 0.9, nesterov = True)\n",
        "model.compile(optimizer = sgd, loss = OBJECTIVE_FUNCTION, metrics = LOSS_METRICS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S-LRbZlE2bXI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Prepare Keras Data Generators\n",
        "\n",
        "Keras `ImageDataGenerator(...)` generates batches of tensor image data with real-time data augmentation. The data will be looped over (in batches). It is useful with large dataset to source, pre-process (resize, color conversion, image augmentation, batch normalize) & supply resulting images in batches to downstream Keras modeling components, namely `fit_generator(...)` &` predict_generator(...) `-vs- `fit(...)` & `predict(...)` for small dataset.\n",
        "\n",
        "Kaggle competition rule expects Dog & Cat to be labeled as 1 & 0. Keras >> `ImageDataGenerator >> flow_from_directory` takes in 'classes' list for mapping it to LABEL indices otherwise treats sub-folders enumerated classes in alphabetical order, i.e., Cat is 0 & Dog is 1."
      ]
    },
    {
      "metadata": {
        "id": "SOuZlftv2BkK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "outputId": "0ed43db4-c20b-4402-88fa-de3bf3f2086e"
      },
      "cell_type": "code",
      "source": [
        "from keras.applications.resnet50 import preprocess_input\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "image_size = IMAGE_RESIZE\n",
        "\n",
        "# preprocessing_function is applied on each image but only after re-sizing & augmentation (resize => augment => pre-process)\n",
        "# Each of the keras.application.resnet* preprocess_input MOSTLY mean BATCH NORMALIZATION (applied on each batch) stabilize the inputs to nonlinear activation functions\n",
        "# Batch Normalization helps in faster convergence\n",
        "data_generator = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "# flow_From_directory generates batches of augmented data (where augmentation can be color conversion, etc)\n",
        "# Both train & valid folders must have NUM_CLASSES sub-folders\n",
        "train_generator = data_generator.flow_from_directory(\n",
        "        '/Images/Train',\n",
        "        target_size=(image_size, image_size),\n",
        "        batch_size=BATCH_SIZE_TRAINING,\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator = data_generator.flow_from_directory(\n",
        "        '/Images/Validation',\n",
        "        target_size=(image_size, image_size),\n",
        "        batch_size=BATCH_SIZE_VALIDATION,\n",
        "        class_mode='categorical') "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-933b254e0238>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mimage_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIMAGE_RESIZE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# preprocessing_function is applied on each image but only after re-sizing & augmentation (resize => augment => pre-process)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'IMAGE_RESIZE' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "w9aQ8kNCLF0q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Connect with the Google Drive"
      ]
    },
    {
      "metadata": {
        "id": "P7qNYNiG7ig7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1ff181c1-238d-4bf4-a127-d158d7c053a2"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.listdir(\".\"))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['.config', 'sample_data']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3Hir2feoLRYa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "b6d245b3-3498-45de-bdae-1bb057412e6e"
      },
      "cell_type": "code",
      "source": [
        "# Authorization\n",
        "\n",
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E: Package 'python-software-properties' has no installation candidate\n",
            "Selecting previously unselected package google-drive-ocamlfuse.\n",
            "(Reading database ... 131294 files and directories currently installed.)\n",
            "Preparing to unpack .../google-drive-ocamlfuse_0.7.3-0ubuntu1~ubuntu18.04.1_amd64.deb ...\n",
            "Unpacking google-drive-ocamlfuse (0.7.3-0ubuntu1~ubuntu18.04.1) ...\n",
            "Setting up google-drive-ocamlfuse (0.7.3-0ubuntu1~ubuntu18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LLbqHrF6LYrK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "c734a2f8-4400-4bca-ec00-9c3eb0f0c6e4"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EAi1JwOQPZcS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# Mount drive to \"drive/\" folder\n",
        "\n",
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "myLP8piyP7ui",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "f9f7960b-eebf-463b-a275-b172dad34ef4"
      },
      "cell_type": "code",
      "source": [
        "print(os.listdir(\"drive/Colab Notebooks/\"))\n",
        "os.chdir(\"drive/Colab Notebooks/\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['The Hello World of Neural Network', 'Week1', 'Week1-Exercise1', 'Week2-Computer Vision on Fashion MINST', 'MINST Digits Recognition', 'Improving Computer Vision Accuracy using Convolutions', 'CNN_Filters and Pools', 'Horse or Human - Image Classification', 'Face Recognition', 'An End-to-End-Data-Science-Framework', 'Azure-aml-real-time-ai', 'Introduction to Pandas', 'First-Steps-With-Tensorflow', 'Introduction to Keras', 'Introduction to Neural Nets', 'Introduction to Matplotlib', 'Introduction to Bokeh', 'Transfer Learning with ResNet50']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SwrCxKjcQDGh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "4aa3affb-d62a-42c3-f002-6e9fa251cbff"
      },
      "cell_type": "code",
      "source": [
        "print(os.listdir(\".\"))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Introduction to Keras', 'Introduction to Bokeh', 'Azure-aml-real-time-ai', 'An End-to-End-Data-Science-Framework', 'Introduction to Neural Nets', 'MINST Digits Recognition', 'Face Recognition', 'CNN_Filters and Pools', 'Week2-Computer Vision on Fashion MINST', 'Week1-Exercise1', 'The Hello World of Neural Network', 'Improving Computer Vision Accuracy using Convolutions', 'Week1', 'Horse or Human - Image Classification', 'First-Steps-With-Tensorflow', 'Introduction to Pandas', 'Transfer Learning with ResNet50', 'Introduction to Matplotlib']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZBETIcTWQyz5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}