{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transfer Learning Using Pretrained ConvNets",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/weiyunna/Deep-Learning-with-Tensorflow/blob/master/Transfer_Learning_Using_Pretrained_ConvNets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "SQxDbahIeOSp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Transfer Learning Using Pretrained ConvNets"
      ]
    },
    {
      "metadata": {
        "id": "xY7DD-HsJ9uf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In this tutorial you will learn how to classify cats vs dogs images by using **transfer learning** from a pre-trained network.\n",
        "\n",
        "A **pre-trained model** is a saved network that was previously trained on a large dataset, typically on a large-scale image-classification task. You either use the pretrained model as it is, or use transfer learning to customize this model to a given task.\n",
        "\n",
        "The intuition behind transfer learning is that if a model trained on a large and general enough dataset, this model will effectively serve as **a generic model of the visual world.** You can then take advantage of these learned feature maps without having to start from scratch training a large model on a large dataset."
      ]
    },
    {
      "metadata": {
        "id": "KTu0YdJ-KVqe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In this notebook, you will try two ways to customize a pretrained model:\n",
        "\n",
        "* **Feature Extraction**: Use the representations of learned by a previous network to extract meaningful features from new samples. You simply add a new classifier, which will be trained from scratch, on top of the pretrained model so that you can **repurpose the feature maps** learned previously for our dataset.\n",
        "You do not need to (re)train the entire model. The base convolutional network already contains features that are generically useful for classifying pictures. However, the final, classification part of the pretrained model is specific to original classification task, and subsequently specific to the set of classes on which the model was trained.\n",
        "\n",
        "* **Fine-Tuning**: Unfreezing a few of the top layers of a frozen model base and jointly training both the newly-added classifier layers and the last layers of the base model. This allows us to \"fine tune\" the higher-order feature representations in the base model in order to make them more relevant for the specific task."
      ]
    },
    {
      "metadata": {
        "id": "_RJiLRPILKjX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "You will follow the general machine learning workflow.\n",
        "\n",
        "* Examine and understand the data\n",
        "* Build an input pipeline, in this case using Keras ImageDataGenerator\n",
        "* Compose our model\n",
        "  * Load in our pretrained base model (and pretrained weights)\n",
        "  * Stack our classification layers on top\n",
        "* Train our model\n",
        "* Evaluate model"
      ]
    },
    {
      "metadata": {
        "id": "_aFObu_deQXk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X2b6j_9TLyB3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "63a12741-87a8-48e0-fc00-39aa156c8c02"
      },
      "cell_type": "code",
      "source": [
        "!pip install -q tensorflow-gpu==2.0.0-alpha0\n",
        "import tensorflow as tf\n",
        "\n",
        "keras = tf.keras"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K    100% |████████████████████████████████| 332.1MB 67kB/s \n",
            "\u001b[K    100% |████████████████████████████████| 419kB 11.4MB/s \n",
            "\u001b[K    100% |████████████████████████████████| 61kB 18.6MB/s \n",
            "\u001b[K    100% |████████████████████████████████| 3.0MB 7.2MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hJHujuVacQ4o",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data Processing"
      ]
    },
    {
      "metadata": {
        "id": "HYQgCVvgcUe3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Data download"
      ]
    },
    {
      "metadata": {
        "id": "zMMaNoRHLzUA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}