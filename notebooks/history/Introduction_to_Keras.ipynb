{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Introduction to Keras",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/weiyunna/Deep-Learning-with-Tensorflow/blob/master/Introduction_to_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "cZoHo48Meui6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Keras is a high-level API to build and train deep learning models. It's used for fast prototyping, advanced research, and production, with three key advantages:\n",
        "\n",
        "*User friendly*\n",
        "\n",
        "*   *User friendly* \n",
        "\n",
        "Keras has a simple, consistent interface optimized for common use cases. It provides clear and actionable feedback for user errors.\n",
        "*  *Modular and composable*\n",
        "\n",
        "Keras models are made by connecting configurable building blocks together, with few restrictions.\n",
        "*   *Easy to extend*\n",
        "\n",
        "Write custom building blocks to express new ideas for research. Create new layers, loss functions, and develop state-of-the-art models.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "eFBY8X4pgcJw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Import tf.keras\n",
        "tf.keras is TensorFlow's implementation of the Keras API specification. This is a high-level API to build and train models that includes first-class support for TensorFlow-specific functionality, such as eager execution, tf.data pipelines, and Estimators. tf.keras makes TensorFlow easier to use without sacrificing flexibility and performance.\n",
        "\n",
        "To get started, import tf.keras as part of your TensorFlow program setup:"
      ]
    },
    {
      "metadata": {
        "id": "7bG6DmtQgJFv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -q pyyaml  # Required to save models in YAML format"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NXyAC-SBgkRS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "3a0081ad-8094-4078-8093-c2441a218c13"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "print(tf.VERSION)\n",
        "print(tf.keras.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.13.1\n",
            "2.2.4-tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WmZHju6cg6Lg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "tf.keras can run any Keras-compatible code, but keep in mind:\n",
        "\n",
        "* The tf.keras version in the latest TensorFlow release might not be the same as the latest keras version from PyPI. Check tf.keras.version.\n",
        "* When saving a model's weights, tf.keras defaults to the checkpoint format. Pass save_format='h5' to use HDF5."
      ]
    },
    {
      "metadata": {
        "id": "zi9bS2m3zoMi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Build a simple model"
      ]
    },
    {
      "metadata": {
        "id": "3n5dyfsihLQP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Sequential model\n",
        "In Keras, you assemble layers to build models. A model is (usually) a graph of layers. The most common type of model is a stack of layers: the tf.keras.Sequential model.\n",
        "\n",
        "To build a simple, fully-connected network (i.e. multi-layer perceptron):"
      ]
    },
    {
      "metadata": {
        "id": "yuZiiLLvgqfY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential()\n",
        "# Adds a densely-connected layer with 64 units to the model:\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "# Add another:\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "# Add a softmax layer with 10 output units:\n",
        "model.add(layers.Dense(10, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xUGLDoTUhrHo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Configure the layers\n",
        "There are many tf.keras.layers available with some common constructor parameters:\n",
        "\n",
        "* **activation**: Set the activation function for the layer. This parameter is specified by the name of a built-in function or as a callable object. By default, no activation is applied.\n",
        "* **kernel_initializer and bias_initializer**: The initialization schemes that create the layer's weights (kernel and bias). This parameter is a name or a callable object. This defaults to the \"Glorot uniform\" initializer.\n",
        "* ** kernel_regularizer and bias_regularizer**: The regularization schemes that apply the layer's weights (kernel and bias), such as L1 or L2 regularization. By default, no regularization is applied.\n",
        "\n",
        "The following instantiates tf.keras.layers.Dense layers using constructor arguments:"
      ]
    },
    {
      "metadata": {
        "id": "mhGqO1__hS_R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "afbb6988-9985-453c-984b-a945a70dcbe0"
      },
      "cell_type": "code",
      "source": [
        "# Create a sigmoid layer:\n",
        "layers.Dense(64, activation='sigmoid')\n",
        "# Or:\n",
        "layers.Dense(64, activation=tf.sigmoid)\n",
        "\n",
        "# A linear layer with L1 regularization of factor 0.01 applied to the kernel matrix:\n",
        "layers.Dense(64, kernel_regularizer=tf.keras.regularizers.l1(0.01))\n",
        "\n",
        "# A linear layer with L2 regularization of factor 0.01 applied to the bias vector:\n",
        "layers.Dense(64, bias_regularizer=tf.keras.regularizers.l2(0.01))\n",
        "\n",
        "# A linear layer with a kernel initialized to a random orthogonal matrix:\n",
        "layers.Dense(64, kernel_initializer='orthogonal')\n",
        "\n",
        "# A linear layer with a bias vector initialized to 2.0s:\n",
        "layers.Dense(64, bias_initializer=tf.keras.initializers.constant(2.0))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.layers.core.Dense at 0x7fb2435d1358>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "mpTr-4CQzj4L",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train and evaluate"
      ]
    },
    {
      "metadata": {
        "id": "8Xj9wNXJiX-Z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Set up training\n",
        "After the model is constructed, configure its learning process by calling the compile method:"
      ]
    },
    {
      "metadata": {
        "id": "jIfZ9xs4iPU4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "91b967d0-23e3-482c-b47f-a0e38705df2b"
      },
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "# Adds a densely-connected layer with 64 units to the model:\n",
        "layers.Dense(64, activation='relu', input_shape=(32,)),\n",
        "# Add another:\n",
        "layers.Dense(64, activation='relu'),\n",
        "# Add a softmax layer with 10 output units:\n",
        "layers.Dense(10, activation='softmax')])\n",
        "\n",
        "model.compile(optimizer=tf.train.AdamOptimizer(0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "q6YPuSo3iu1g",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "tf.keras.Model.compile takes three important arguments:\n",
        "\n",
        "* optimizer: This object specifies the training procedure. Pass it optimizer instances from the tf.train module, such as tf.train.AdamOptimizer, tf.train.RMSPropOptimizer, or tf.train.GradientDescentOptimizer.\n",
        "* loss: The function to minimize during optimization. Common choices include mean square error (mse), categorical_crossentropy, and binary_crossentropy. Loss functions are specified by name or by passing a callable object from the tf.keras.losses module.\n",
        "* metrics: Used to monitor training. These are string names or callables from the tf.keras.metrics module.\n",
        "\n",
        "The following shows a few examples of configuring a model for training:"
      ]
    },
    {
      "metadata": {
        "id": "wB1Tm8ovihIG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "2896aa46-5f84-45b7-bbdb-7386d4facba5"
      },
      "cell_type": "code",
      "source": [
        "# Configure a model for mean-squared error regression.\n",
        "model.compile(optimizer=tf.train.AdamOptimizer(0.01),\n",
        "              loss='mse',       # mean squared error\n",
        "              metrics=['mae'])  # mean absolute error\n",
        "\n",
        "# Configure a model for categorical classification.\n",
        "model.compile(optimizer=tf.train.RMSPropOptimizer(0.01),\n",
        "              loss=tf.keras.losses.categorical_crossentropy,\n",
        "              metrics=[tf.keras.metrics.categorical_accuracy])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Uonq83WojN-Q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Input NumPy data\n",
        "For small datasets, use in-memory NumPy arrays to train and evaluate a model. The model is \"fit\" to the training data using the fit method:"
      ]
    },
    {
      "metadata": {
        "id": "2qZ4Ucqci_ht",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        },
        "outputId": "1a83d4fe-4e12-4ecf-fc8e-d9aa5c3f1702"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "data = np.random.random((1000, 32))\n",
        "labels = np.random.random((1000, 10))\n",
        "\n",
        "model.fit(data, labels, epochs=10, batch_size=32)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/10\n",
            "1000/1000 [==============================] - 0s 417us/sample - loss: 11.5529 - categorical_accuracy: 0.0780\n",
            "Epoch 2/10\n",
            "1000/1000 [==============================] - 0s 53us/sample - loss: 11.5034 - categorical_accuracy: 0.0920\n",
            "Epoch 3/10\n",
            "1000/1000 [==============================] - 0s 53us/sample - loss: 11.4847 - categorical_accuracy: 0.1170\n",
            "Epoch 4/10\n",
            "1000/1000 [==============================] - 0s 50us/sample - loss: 11.4785 - categorical_accuracy: 0.0880\n",
            "Epoch 5/10\n",
            "1000/1000 [==============================] - 0s 50us/sample - loss: 11.4741 - categorical_accuracy: 0.0990\n",
            "Epoch 6/10\n",
            "1000/1000 [==============================] - 0s 49us/sample - loss: 11.4777 - categorical_accuracy: 0.0850\n",
            "Epoch 7/10\n",
            "1000/1000 [==============================] - 0s 52us/sample - loss: 11.4705 - categorical_accuracy: 0.1230\n",
            "Epoch 8/10\n",
            "1000/1000 [==============================] - 0s 47us/sample - loss: 11.4696 - categorical_accuracy: 0.1150\n",
            "Epoch 9/10\n",
            "1000/1000 [==============================] - 0s 49us/sample - loss: 11.4684 - categorical_accuracy: 0.1230\n",
            "Epoch 10/10\n",
            "1000/1000 [==============================] - 0s 52us/sample - loss: 11.4650 - categorical_accuracy: 0.1100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb242fd59b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "8_EGgqrpjp0h",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "tf.keras.Model.fit takes three important arguments:\n",
        "\n",
        "* epochs: Training is structured into epochs. An epoch is one iteration over the entire input data (this is done in smaller batches).\n",
        "* batch_size: When passed NumPy data, the model slices the data into smaller batches and iterates over these batches during training. This integer specifies the size of each batch. Be aware that the last batch may be smaller if the total number of samples is not divisible by the batch size.\n",
        "* validation_data: When prototyping a model, you want to easily monitor its performance on some validation data. Passing this argument—a tuple of inputs and labels—allows the model to display the loss and metrics in inference mode for the passed data, at the end of each epoch.\n",
        "\n",
        "Here's an example using validation_data:"
      ]
    },
    {
      "metadata": {
        "id": "DR9XJWyBjU_a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "outputId": "bf62e3d2-e123-450a-8a21-88da31ba6b19"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "data = np.random.random((1000, 32))\n",
        "labels = np.random.random((1000, 10))\n",
        "\n",
        "val_data = np.random.random((100, 32))\n",
        "val_labels = np.random.random((100, 10))\n",
        "\n",
        "model.fit(data, labels, epochs=10, batch_size=32,\n",
        "          validation_data=(val_data, val_labels))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1000 samples, validate on 100 samples\n",
            "Epoch 1/10\n",
            "1000/1000 [==============================] - 0s 95us/sample - loss: 11.5785 - categorical_accuracy: 0.0860 - val_loss: 11.2762 - val_categorical_accuracy: 0.1400\n",
            "Epoch 2/10\n",
            "1000/1000 [==============================] - 0s 53us/sample - loss: 11.5750 - categorical_accuracy: 0.1160 - val_loss: 11.2858 - val_categorical_accuracy: 0.1300\n",
            "Epoch 3/10\n",
            "1000/1000 [==============================] - 0s 55us/sample - loss: 11.5722 - categorical_accuracy: 0.1170 - val_loss: 11.2826 - val_categorical_accuracy: 0.1100\n",
            "Epoch 4/10\n",
            "1000/1000 [==============================] - 0s 56us/sample - loss: 11.5733 - categorical_accuracy: 0.1090 - val_loss: 11.2870 - val_categorical_accuracy: 0.1800\n",
            "Epoch 5/10\n",
            "1000/1000 [==============================] - 0s 57us/sample - loss: 11.5725 - categorical_accuracy: 0.1070 - val_loss: 11.2817 - val_categorical_accuracy: 0.1700\n",
            "Epoch 6/10\n",
            "1000/1000 [==============================] - 0s 56us/sample - loss: 11.5709 - categorical_accuracy: 0.1030 - val_loss: 11.2927 - val_categorical_accuracy: 0.0600\n",
            "Epoch 7/10\n",
            "1000/1000 [==============================] - 0s 53us/sample - loss: 11.5703 - categorical_accuracy: 0.1010 - val_loss: 11.3082 - val_categorical_accuracy: 0.0800\n",
            "Epoch 8/10\n",
            "1000/1000 [==============================] - 0s 53us/sample - loss: 11.5696 - categorical_accuracy: 0.1090 - val_loss: 11.2905 - val_categorical_accuracy: 0.1000\n",
            "Epoch 9/10\n",
            "1000/1000 [==============================] - 0s 55us/sample - loss: 11.5687 - categorical_accuracy: 0.1100 - val_loss: 11.2998 - val_categorical_accuracy: 0.1400\n",
            "Epoch 10/10\n",
            "1000/1000 [==============================] - 0s 59us/sample - loss: 11.5675 - categorical_accuracy: 0.1130 - val_loss: 11.2983 - val_categorical_accuracy: 0.0800\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb23e7640b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "wT9NMldXkEdV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Input tf.data datasets\n",
        "Use the Datasets API to scale to large datasets or multi-device training. Pass a tf.data.Dataset instance to the fit method:"
      ]
    },
    {
      "metadata": {
        "id": "hYKkxL3hj5Ue",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "1184285f-693f-49f8-e011-556ee53b1777"
      },
      "cell_type": "code",
      "source": [
        "  # Instantiates a toy dataset instance:\n",
        "dataset = tf.data.Dataset.from_tensor_slices((data, labels))\n",
        "dataset = dataset.batch(32)\n",
        "dataset = dataset.repeat()\n",
        "\n",
        "# Don't forget to specify `steps_per_epoch` when calling `fit` on a dataset.\n",
        "model.fit(dataset, epochs=10, steps_per_epoch=30)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 11.5949 - categorical_accuracy: 0.1229\n",
            "Epoch 2/10\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 11.5539 - categorical_accuracy: 0.1068\n",
            "Epoch 3/10\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 11.5197 - categorical_accuracy: 0.1303\n",
            "Epoch 4/10\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 11.5634 - categorical_accuracy: 0.1261\n",
            "Epoch 5/10\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 11.5322 - categorical_accuracy: 0.1335\n",
            "Epoch 6/10\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 11.5700 - categorical_accuracy: 0.1250\n",
            "Epoch 7/10\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 11.5242 - categorical_accuracy: 0.1389\n",
            "Epoch 8/10\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 11.5243 - categorical_accuracy: 0.1410\n",
            "Epoch 9/10\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 11.5210 - categorical_accuracy: 0.1314\n",
            "Epoch 10/10\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 11.5472 - categorical_accuracy: 0.1357\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb23e764898>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "k3MX_wVpknOo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Here, the fit method uses the steps_per_epoch argument—this is the number of training steps the model runs before it moves to the next epoch. Since the Dataset yields batches of data, this snippet does not require a batch_size.\n",
        "\n",
        "Datasets can also be used for validation:"
      ]
    },
    {
      "metadata": {
        "id": "fbtVQwSukJb6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "9cba9d13-70a6-413c-ebc3-e4498be4ebe4"
      },
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((data, labels))\n",
        "dataset = dataset.batch(32).repeat()\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_data, val_labels))\n",
        "val_dataset = val_dataset.batch(32).repeat()\n",
        "\n",
        "model.fit(dataset, epochs=10, steps_per_epoch=30,\n",
        "          validation_data=val_dataset,\n",
        "          validation_steps=3)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 11.5752 - categorical_accuracy: 0.1354 - val_loss: 11.3028 - val_categorical_accuracy: 0.1250\n",
            "Epoch 2/10\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 11.5276 - categorical_accuracy: 0.1346 - val_loss: 11.3563 - val_categorical_accuracy: 0.0882\n",
            "Epoch 3/10\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 11.4936 - categorical_accuracy: 0.1549 - val_loss: 11.4747 - val_categorical_accuracy: 0.1029\n",
            "Epoch 4/10\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 11.5368 - categorical_accuracy: 0.1581 - val_loss: 11.6896 - val_categorical_accuracy: 0.1029\n",
            "Epoch 5/10\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 11.5075 - categorical_accuracy: 0.1474 - val_loss: 11.3317 - val_categorical_accuracy: 0.1250\n",
            "Epoch 6/10\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 11.5459 - categorical_accuracy: 0.1453 - val_loss: 11.3564 - val_categorical_accuracy: 0.1176\n",
            "Epoch 7/10\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 11.5024 - categorical_accuracy: 0.1400 - val_loss: 11.5096 - val_categorical_accuracy: 0.1324\n",
            "Epoch 8/10\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 11.5027 - categorical_accuracy: 0.1517 - val_loss: 11.6397 - val_categorical_accuracy: 0.1324\n",
            "Epoch 9/10\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 11.4984 - categorical_accuracy: 0.1677 - val_loss: 11.3416 - val_categorical_accuracy: 0.1354\n",
            "Epoch 10/10\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 11.5275 - categorical_accuracy: 0.1496 - val_loss: 11.3833 - val_categorical_accuracy: 0.1029\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb23d6b95f8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "fDBZqFomkxkn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Evaluate and predict\n",
        "\n",
        "The tf.keras.Model.evaluate and tf.keras.Model.predict methods can use NumPy data and a tf.data.Dataset.\n",
        "\n",
        "To evaluate the inference-mode loss and metrics for the data provided:"
      ]
    },
    {
      "metadata": {
        "id": "AdT9MHzQksGv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "92933cc3-e34d-40bb-d8a8-fc03d973e2df"
      },
      "cell_type": "code",
      "source": [
        "data = np.random.random((1000, 32))\n",
        "labels = np.random.random((1000, 10))\n",
        "\n",
        "model.evaluate(data, labels, batch_size=32)\n",
        "\n",
        "model.evaluate(dataset, steps=30)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 0s 78us/sample - loss: 11.4886 - categorical_accuracy: 0.1010\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 11.5687 - categorical_accuracy: 0.1708\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[11.568681335449218, 0.17083333]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "CZ3XXuvjk8MI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "And to predict the output of the last layer in inference for the data provided, as a NumPy array:"
      ]
    },
    {
      "metadata": {
        "id": "0y4J_Hhbk5M5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bda1d180-d441-435d-8b5d-67e3933bd86b"
      },
      "cell_type": "code",
      "source": [
        "result = model.predict(data, batch_size=32)\n",
        "print(result.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eWms3iJXwXd4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Build advanced models"
      ]
    },
    {
      "metadata": {
        "id": "AY11e3V9v3Go",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### Functional API\n",
        "The tf.keras.Sequential model is a simple stack of layers that cannot represent arbitrary models. Use the Keras functional API to build complex model topologies such as:\n",
        "\n",
        "* Multi-input models,\n",
        "* Multi-output models,\n",
        "* Models with shared layers (the same layer called several times),\n",
        "* Models with non-sequential data flows (e.g. residual connections).\n",
        "\n",
        "Building a model with the functional API works like this:\n",
        "\n",
        "1. A layer instance is callable and returns a tensor.\n",
        "2. Input tensors and output tensors are used to define a tf.keras.Model instance.\n",
        "3. This model is trained just like the Sequential model.\n",
        "\n",
        "The following example uses the functional API to build a simple, fully-connected network:\n"
      ]
    },
    {
      "metadata": {
        "id": "CbjKSyHIr3go",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Model subclassing\n",
        "Build a fully-customizable model by subclassing tf.keras.Model and defining your own forward pass. Create layers in the __init__ method and set them as attributes of the class instance. Define the forward pass in the call method.\n",
        "\n",
        "Model subclassing is particularly useful when eager execution is enabled since the forward pass can be written imperatively."
      ]
    },
    {
      "metadata": {
        "id": "lQKMk7xcsIAw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "\n",
        "  def __init__(self, num_classes=10):\n",
        "    super(MyModel, self).__init__(name='my_model')\n",
        "    self.num_classes = num_classes\n",
        "    # Define your layers here.\n",
        "    self.dense_1 = layers.Dense(32, activation='relu')\n",
        "    self.dense_2 = layers.Dense(num_classes, activation='sigmoid')\n",
        "\n",
        "  def call(self, inputs):\n",
        "    # Define your forward pass here,\n",
        "    # using layers you previously defined (in `__init__`).\n",
        "    x = self.dense_1(inputs)\n",
        "    return self.dense_2(x)\n",
        "\n",
        "  def compute_output_shape(self, input_shape):\n",
        "    # You need to override this function if you want to use the subclassed model\n",
        "    # as part of a functional-style model.\n",
        "    # Otherwise, this method is optional.\n",
        "    shape = tf.TensorShape(input_shape).as_list()\n",
        "    shape[-1] = self.num_classes\n",
        "    return tf.TensorShape(shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2SOxvAPosNuI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Instantiate the new model class:"
      ]
    },
    {
      "metadata": {
        "id": "FWxQy-KgsRD6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "683265b7-f5c4-4cb9-872c-516a6d88f307"
      },
      "cell_type": "code",
      "source": [
        "model = MyModel(num_classes=10)\n",
        "\n",
        "# The compile step specifies the training configuration.\n",
        "model.compile(optimizer=tf.train.RMSPropOptimizer(0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Trains for 5 epochs.\n",
        "model.fit(data, labels, batch_size=32, epochs=5)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1000/1000 [==============================] - 0s 130us/sample - loss: 11.5672 - acc: 0.0900\n",
            "Epoch 2/5\n",
            "1000/1000 [==============================] - 0s 46us/sample - loss: 11.5274 - acc: 0.0900\n",
            "Epoch 3/5\n",
            "1000/1000 [==============================] - 0s 41us/sample - loss: 11.4811 - acc: 0.0960\n",
            "Epoch 4/5\n",
            "1000/1000 [==============================] - 0s 42us/sample - loss: 11.4659 - acc: 0.0940\n",
            "Epoch 5/5\n",
            "1000/1000 [==============================] - 0s 43us/sample - loss: 11.4603 - acc: 0.1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb23ad9ebe0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "kd0m2QnqryNx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Custom layers\n",
        "Create a custom layer by subclassing tf.keras.layers.Layer and implementing the following methods:\n",
        "\n",
        "* build: Create the weights of the layer. Add weights with the add_weight method.\n",
        "* call: Define the forward pass.\n",
        "* compute_output_shape: Specify how to compute the output shape of the layer given the input shape.\n",
        "* Optionally, a layer can be serialized by implementing the get_config method and the from_config class method.\n",
        "\n",
        "Here's an example of a custom layer that implements a matmul of an input with a kernel matrix:"
      ]
    },
    {
      "metadata": {
        "id": "AJdhORDak_Md",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class MyLayer(layers.Layer):\n",
        "\n",
        "  def __init__(self, output_dim, **kwargs):\n",
        "    self.output_dim = output_dim\n",
        "    super(MyLayer, self).__init__(**kwargs)\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    shape = tf.TensorShape((input_shape[1], self.output_dim))\n",
        "    # Create a trainable weight variable for this layer.\n",
        "    self.kernel = self.add_weight(name='kernel',\n",
        "                                  shape=shape,\n",
        "                                  initializer='uniform',\n",
        "                                  trainable=True)\n",
        "    # Make sure to call the `build` method at the end\n",
        "    super(MyLayer, self).build(input_shape)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return tf.matmul(inputs, self.kernel)\n",
        "\n",
        "  def compute_output_shape(self, input_shape):\n",
        "    shape = tf.TensorShape(input_shape).as_list()\n",
        "    shape[-1] = self.output_dim\n",
        "    return tf.TensorShape(shape)\n",
        "\n",
        "  def get_config(self):\n",
        "    base_config = super(MyLayer, self).get_config()\n",
        "    base_config['output_dim'] = self.output_dim\n",
        "    return base_config\n",
        "\n",
        "  @classmethod\n",
        "  def from_config(cls, config):\n",
        "    return cls(**config)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vgUM8J8Nsskg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Create a model using your custom layer:"
      ]
    },
    {
      "metadata": {
        "id": "S1ciGIyeso3n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "82595ecb-640e-490c-a1de-a795d15fd2bb"
      },
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    MyLayer(10),\n",
        "    layers.Activation('softmax')])\n",
        "\n",
        "# The compile step specifies the training configuration\n",
        "model.compile(optimizer=tf.train.RMSPropOptimizer(0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Trains for 5 epochs.\n",
        "model.fit(data, labels, batch_size=32, epochs=5)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1000/1000 [==============================] - 0s 125us/sample - loss: 11.4595 - acc: 0.0910\n",
            "Epoch 2/5\n",
            "1000/1000 [==============================] - 0s 43us/sample - loss: 11.4513 - acc: 0.0990\n",
            "Epoch 3/5\n",
            "1000/1000 [==============================] - 0s 45us/sample - loss: 11.4482 - acc: 0.0990\n",
            "Epoch 4/5\n",
            "1000/1000 [==============================] - 0s 47us/sample - loss: 11.4469 - acc: 0.0900\n",
            "Epoch 5/5\n",
            "1000/1000 [==============================] - 0s 42us/sample - loss: 11.4460 - acc: 0.0980\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb2437895c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "HVFul9MkuEwo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Callbacks\n",
        "A callback is an object passed to a model to customize and extend its behavior during training. You can write your own custom callback, or use the built-in tf.keras.callbacks that include:\n",
        "\n",
        "* tf.keras.callbacks.ModelCheckpoint: Save checkpoints of your model at regular intervals.\n",
        "* tf.keras.callbacks.LearningRateScheduler: Dynamically change the learning rate.\n",
        "* tf.keras.callbacks.EarlyStopping: Interrupt training when validation performance has stopped improving.\n",
        "* tf.keras.callbacks.TensorBoard: Monitor the model's behavior using TensorBoard.\n",
        "\n",
        "\n",
        "To use a tf.keras.callbacks.Callback, pass it to the model's fit method:"
      ]
    },
    {
      "metadata": {
        "id": "xlQYnc9HsvSB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "aefe5c67-edb4-4a69-ce25-cf750c0e61a7"
      },
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "  # Interrupt training if `val_loss` stops improving for over 2 epochs\n",
        "  tf.keras.callbacks.EarlyStopping(patience=2, monitor='val_loss'),\n",
        "  # Write TensorBoard logs to `./logs` directory\n",
        "  tf.keras.callbacks.TensorBoard(log_dir='./logs')\n",
        "]\n",
        "model.fit(data, labels, batch_size=32, epochs=5, callbacks=callbacks,\n",
        "          validation_data=(val_data, val_labels))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1000 samples, validate on 100 samples\n",
            "Epoch 1/5\n",
            "1000/1000 [==============================] - 0s 110us/sample - loss: 11.4436 - acc: 0.0940 - val_loss: 11.2864 - val_acc: 0.0900\n",
            "Epoch 2/5\n",
            "1000/1000 [==============================] - 0s 56us/sample - loss: 11.4428 - acc: 0.0950 - val_loss: 11.2885 - val_acc: 0.0900\n",
            "Epoch 3/5\n",
            "1000/1000 [==============================] - 0s 46us/sample - loss: 11.4409 - acc: 0.1040 - val_loss: 11.2925 - val_acc: 0.0700\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb23a82b7f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "2qaxhbhxxk0h",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Save and restore\n"
      ]
    },
    {
      "metadata": {
        "id": "7Z5o4hDauj2i",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Weights only\n",
        "Save and load the weights of a model using tf.keras.Model.save_weights:"
      ]
    },
    {
      "metadata": {
        "id": "6i8S7TK2uXQ7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "layers.Dense(64, activation='relu', input_shape=(32,)),\n",
        "layers.Dense(10, activation='softmax')])\n",
        "\n",
        "model.compile(optimizer=tf.train.AdamOptimizer(0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kU9D-Fv6wglG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "ea963f40-ca3f-4b40-def4-fca19d82b207"
      },
      "cell_type": "code",
      "source": [
        "# Save weights to a TensorFlow Checkpoint file\n",
        "model.save_weights('./weights/my_model')\n",
        "\n",
        "# Restore the model's state,\n",
        "# this requires a model with the same architecture.\n",
        "model.load_weights('./weights/my_model')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py:1436: update_checkpoint_state (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.train.CheckpointManager to manage checkpoints rather than manually editing the Checkpoint proto.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.checkpointable.util.CheckpointLoadStatus at 0x7fb239e45208>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "3iu_nObHwomh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "By default, this saves the model's weights in the TensorFlow checkpoint file format. Weights can also be saved to the Keras HDF5 format (the default for the multi-backend implementation of Keras):"
      ]
    },
    {
      "metadata": {
        "id": "WRK12p1pwi91",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Save weights to a HDF5 file\n",
        "model.save_weights('my_model.h5', save_format='h5')\n",
        "\n",
        "# Restore the model's state\n",
        "model.load_weights('my_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qHu-mbdwwvlw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Configuration only\n",
        "A model's configuration can be saved—this serializes the model architecture without any weights. A saved configuration can recreate and initialize the same model, even without the code that defined the original model. Keras supports JSON and YAML serialization formats:"
      ]
    },
    {
      "metadata": {
        "id": "HdxsEnnIws8l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "e880cae8-6aca-4c8e-b8bb-313874c4a58b"
      },
      "cell_type": "code",
      "source": [
        "# Serialize a model to JSON format\n",
        "json_string = model.to_json()\n",
        "json_string"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\"class_name\": \"Sequential\", \"config\": {\"name\": \"sequential_3\", \"layers\": [{\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_14\", \"trainable\": true, \"batch_input_shape\": [null, 32], \"dtype\": \"float32\", \"units\": 64, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null, \"dtype\": \"float32\"}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {\"dtype\": \"float32\"}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_15\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 10, \"activation\": \"softmax\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null, \"dtype\": \"float32\"}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {\"dtype\": \"float32\"}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}]}, \"keras_version\": \"2.2.4-tf\", \"backend\": \"tensorflow\"}'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "f6Cu_brHw0Qg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 672
        },
        "outputId": "70063951-a6a6-4f94-9559-adf20ef3de2a"
      },
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pprint\n",
        "pprint.pprint(json.loads(json_string))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'backend': 'tensorflow',\n",
            " 'class_name': 'Sequential',\n",
            " 'config': {'layers': [{'class_name': 'Dense',\n",
            "                        'config': {'activation': 'relu',\n",
            "                                   'activity_regularizer': None,\n",
            "                                   'batch_input_shape': [None, 32],\n",
            "                                   'bias_constraint': None,\n",
            "                                   'bias_initializer': {'class_name': 'Zeros',\n",
            "                                                        'config': {'dtype': 'float32'}},\n",
            "                                   'bias_regularizer': None,\n",
            "                                   'dtype': 'float32',\n",
            "                                   'kernel_constraint': None,\n",
            "                                   'kernel_initializer': {'class_name': 'GlorotUniform',\n",
            "                                                          'config': {'dtype': 'float32',\n",
            "                                                                     'seed': None}},\n",
            "                                   'kernel_regularizer': None,\n",
            "                                   'name': 'dense_14',\n",
            "                                   'trainable': True,\n",
            "                                   'units': 64,\n",
            "                                   'use_bias': True}},\n",
            "                       {'class_name': 'Dense',\n",
            "                        'config': {'activation': 'softmax',\n",
            "                                   'activity_regularizer': None,\n",
            "                                   'bias_constraint': None,\n",
            "                                   'bias_initializer': {'class_name': 'Zeros',\n",
            "                                                        'config': {'dtype': 'float32'}},\n",
            "                                   'bias_regularizer': None,\n",
            "                                   'dtype': 'float32',\n",
            "                                   'kernel_constraint': None,\n",
            "                                   'kernel_initializer': {'class_name': 'GlorotUniform',\n",
            "                                                          'config': {'dtype': 'float32',\n",
            "                                                                     'seed': None}},\n",
            "                                   'kernel_regularizer': None,\n",
            "                                   'name': 'dense_15',\n",
            "                                   'trainable': True,\n",
            "                                   'units': 10,\n",
            "                                   'use_bias': True}}],\n",
            "            'name': 'sequential_3'},\n",
            " 'keras_version': '2.2.4-tf'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NfpenPM0w8gy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Recreate the model (newly initialized) from the JSON:"
      ]
    },
    {
      "metadata": {
        "id": "aDejU_wxw5NK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fresh_model = tf.keras.models.model_from_json(json_string)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sldPQGJ-xGrJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Serializing a model to YAML format requires that you install pyyaml before you import TensorFlow:"
      ]
    },
    {
      "metadata": {
        "id": "iO2E-3QIw-0N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 790
        },
        "outputId": "b6c4dd40-95b3-41f4-b516-a5ec64e7e1be"
      },
      "cell_type": "code",
      "source": [
        "yaml_string = model.to_yaml()\n",
        "print(yaml_string)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "backend: tensorflow\n",
            "class_name: Sequential\n",
            "config:\n",
            "  layers:\n",
            "  - class_name: Dense\n",
            "    config:\n",
            "      activation: relu\n",
            "      activity_regularizer: null\n",
            "      batch_input_shape: !!python/tuple [null, 32]\n",
            "      bias_constraint: null\n",
            "      bias_initializer:\n",
            "        class_name: Zeros\n",
            "        config: {dtype: float32}\n",
            "      bias_regularizer: null\n",
            "      dtype: float32\n",
            "      kernel_constraint: null\n",
            "      kernel_initializer:\n",
            "        class_name: GlorotUniform\n",
            "        config: {dtype: float32, seed: null}\n",
            "      kernel_regularizer: null\n",
            "      name: dense_14\n",
            "      trainable: true\n",
            "      units: 64\n",
            "      use_bias: true\n",
            "  - class_name: Dense\n",
            "    config:\n",
            "      activation: softmax\n",
            "      activity_regularizer: null\n",
            "      bias_constraint: null\n",
            "      bias_initializer:\n",
            "        class_name: Zeros\n",
            "        config: {dtype: float32}\n",
            "      bias_regularizer: null\n",
            "      dtype: float32\n",
            "      kernel_constraint: null\n",
            "      kernel_initializer:\n",
            "        class_name: GlorotUniform\n",
            "        config: {dtype: float32, seed: null}\n",
            "      kernel_regularizer: null\n",
            "      name: dense_15\n",
            "      trainable: true\n",
            "      units: 10\n",
            "      use_bias: true\n",
            "  name: sequential_3\n",
            "keras_version: 2.2.4-tf\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GM6hmDdPxLqB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Recreate the model from the YAML:"
      ]
    },
    {
      "metadata": {
        "id": "1yOO7eSMxJfe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fresh_model = tf.keras.models.model_from_yaml(yaml_string)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i5k-KmirxQnQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Caution: Subclassed models are not serializable because their architecture is defined by the Python code in the body of the call method."
      ]
    },
    {
      "metadata": {
        "id": "nZrvIGCTxadh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### entire model\n",
        "\n",
        "The entire model can be saved to a file that contains the weight values, the model's configuration, and even the optimizer's configuration. This allows you to checkpoint a model and resume training later—from the exact same state—without access to the original code."
      ]
    },
    {
      "metadata": {
        "id": "lN1P_rwKxO6G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "af9e3345-bf5f-4a90-ff25-bca3a886ac52"
      },
      "cell_type": "code",
      "source": [
        "# Create a trivial model\n",
        "model = tf.keras.Sequential([\n",
        "  layers.Dense(10, activation='softmax', input_shape=(32,)),\n",
        "  layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(data, labels, batch_size=32, epochs=5)\n",
        "\n",
        "\n",
        "# Save entire model to a HDF5 file\n",
        "model.save('my_model.h5')\n",
        "\n",
        "# Recreate the exact same model, including weights and optimizer.\n",
        "model = tf.keras.models.load_model('my_model.h5')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1000/1000 [==============================] - 0s 194us/sample - loss: 11.4586 - acc: 0.1010\n",
            "Epoch 2/5\n",
            "1000/1000 [==============================] - 0s 50us/sample - loss: 11.4501 - acc: 0.1050\n",
            "Epoch 3/5\n",
            "1000/1000 [==============================] - 0s 50us/sample - loss: 11.4471 - acc: 0.1040\n",
            "Epoch 4/5\n",
            "1000/1000 [==============================] - 0s 53us/sample - loss: 11.4454 - acc: 0.1030\n",
            "Epoch 5/5\n",
            "1000/1000 [==============================] - 0s 49us/sample - loss: 11.4447 - acc: 0.0980\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QjCo5ChYyaG5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Eager execution\n",
        "Eager execution is an imperative programming environment that evaluates operations immediately. This is not required for Keras, but is supported by tf.keras and useful for inspecting your program and debugging.\n",
        "\n",
        "All of the tf.keras model-building APIs are compatible with eager execution. And while the Sequential and functional APIs can be used, eager execution especially benefits model subclassing and building custom layers—the APIs that require you to write the forward pass as code (instead of the APIs that create models by assembling existing layers).\n",
        "\n",
        "See the eager execution guide for examples of using Keras models with custom training loops and tf.GradientTape."
      ]
    },
    {
      "metadata": {
        "id": "aIxsgKhzyoJY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Distribution"
      ]
    },
    {
      "metadata": {
        "id": "hD8TBUyGylcR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Estimators\n",
        "The Estimators API is used for training models for distributed environments. This targets industry use cases such as distributed training on large datasets that can export a model for production.\n",
        "\n",
        "A tf.keras.Model can be trained with the tf.estimator API by converting the model to an tf.estimator.Estimator object with tf.keras.estimator.model_to_estimator. See Creating Estimators from Keras models."
      ]
    },
    {
      "metadata": {
        "id": "nRobPpsXxshP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "outputId": "72fed8c3-ba45-4f60-b309-b64f9dd3c7ca"
      },
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([layers.Dense(10,activation='softmax'),\n",
        "                          layers.Dense(10,activation='softmax')])\n",
        "\n",
        "model.compile(optimizer=tf.train.RMSPropOptimizer(0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "estimator = tf.keras.estimator.model_to_estimator(model)\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpare586sk\n",
            "INFO:tensorflow:Using the Keras model provided.\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpare586sk', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fb23a7ae470>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vPkcd5Eby_jU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Multiple GPUs\n",
        "tf.keras models can run on multiple GPUs using tf.contrib.distribute.DistributionStrategy. This API provides distributed training on multiple GPUs with almost no changes to existing code.\n",
        "\n",
        "Currently, tf.contrib.distribute.MirroredStrategy is the only supported distribution strategy. MirroredStrategy does in-graph replication with synchronous training using all-reduce on a single machine. To use DistributionStrategy with Keras, convert the tf.keras.Model to a tf.estimator.Estimator with tf.keras.estimator.model_to_estimator, then train the estimator\n",
        "\n",
        "The following example distributes a tf.keras.Model across multiple GPUs on a single machine.\n",
        "\n",
        "First, define a simple model:"
      ]
    },
    {
      "metadata": {
        "id": "L9ThsQi4ywL_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "3f7b2175-6f5d-45df-dfcd-a31f2132b840"
      },
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential()\n",
        "model.add(layers.Dense(16, activation='relu', input_shape=(10,)))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "optimizer = tf.train.GradientDescentOptimizer(0.2)\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "model.summary()\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_20 (Dense)             (None, 16)                176       \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 193\n",
            "Trainable params: 193\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UEK5lx0IzKqG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Define an input pipeline. The input_fn returns a tf.data.Dataset object used to distribute the data across multiple devices—with each device processing a slice of the input batch."
      ]
    },
    {
      "metadata": {
        "id": "wh8o2AUWzD_W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def input_fn():\n",
        "  x = np.random.random((1024, 10))\n",
        "  y = np.random.randint(2, size=(1024, 1))\n",
        "  x = tf.cast(x, tf.float32)\n",
        "  dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
        "  dataset = dataset.repeat(10)\n",
        "  dataset = dataset.batch(32)\n",
        "  return dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YXNRLI5ezQWJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Next, create a tf.estimator.RunConfig and set the train_distribute argument to the tf.contrib.distribute.MirroredStrategy instance. When creating MirroredStrategy, you can specify a list of devices or set the num_gpus argument. The default uses all available GPUs, like the following:"
      ]
    },
    {
      "metadata": {
        "id": "wLj_1bdbzNIB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "e5d778f4-9622-4cc8-d76e-f87abb008fd4"
      },
      "cell_type": "code",
      "source": [
        "strategy = tf.contrib.distribute.MirroredStrategy()\n",
        "config = tf.estimator.RunConfig(train_distribute=strategy)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "INFO:tensorflow:Device is available but not used by distribute strategy: /device:XLA_CPU:0\n",
            "WARNING:tensorflow:Not all devices in `tf.distribute.Strategy` are visible to TensorFlow.\n",
            "INFO:tensorflow:Initializing RunConfig with distribution strategies.\n",
            "INFO:tensorflow:Not using Distribute Coordinator.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fZ6R0iFYzV0B",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Convert the Keras model to a tf.estimator.Estimator instance:"
      ]
    },
    {
      "metadata": {
        "id": "IBQl6YvszTqH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "outputId": "fd826018-2c17-4c9c-aa65-c15ee266cb76"
      },
      "cell_type": "code",
      "source": [
        "keras_estimator = tf.keras.estimator.model_to_estimator(\n",
        "  keras_model=model,\n",
        "  config=config,\n",
        "  model_dir='/tmp/model_dir')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using the Keras model provided.\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/model_dir', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': <tensorflow.contrib.distribute.python.mirrored_strategy.MirroredStrategy object at 0x7fb233054908>, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fb233054b00>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_distribute_coordinator_mode': None}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OSrglfQazbnB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Finally, train the Estimator instance by providing the input_fn and steps arguments:"
      ]
    },
    {
      "metadata": {
        "id": "K1g4aJRbzYci",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "26f6cb99-9916-4b5f-edda-b32c908a0f81"
      },
      "cell_type": "code",
      "source": [
        "keras_estimator.train(input_fn=input_fn, steps=10)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from='/tmp/model_dir/keras/keras_model.ckpt', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})\n",
            "INFO:tensorflow:Warm-starting from: ('/tmp/model_dir/keras/keras_model.ckpt',)\n",
            "INFO:tensorflow:Warm-starting variable: dense_20/kernel; prev_var_name: Unchanged\n",
            "INFO:tensorflow:Warm-starting variable: dense_20/bias; prev_var_name: Unchanged\n",
            "INFO:tensorflow:Warm-starting variable: dense_21/kernel; prev_var_name: Unchanged\n",
            "INFO:tensorflow:Warm-starting variable: dense_21/bias; prev_var_name: Unchanged\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/model_dir/model.ckpt.\n",
            "INFO:tensorflow:Initialize strategy\n",
            "INFO:tensorflow:loss = 0.6984923, step = 0\n",
            "INFO:tensorflow:Saving checkpoints for 10 into /tmp/model_dir/model.ckpt.\n",
            "INFO:tensorflow:Finalize strategy.\n",
            "INFO:tensorflow:Loss for final step: 0.6952334.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow_estimator.python.estimator.estimator.Estimator at 0x7fb233054be0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "metadata": {
        "id": "DIGkqJc5ze5X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}