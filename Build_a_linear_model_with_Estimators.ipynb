{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Build a linear model with Estimators",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/weiyunna/Deep-Learning-with-Tensorflow/blob/master/Build_a_linear_model_with_Estimators.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "6vQPvYDLo5FT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Build a linear model with Estimators"
      ]
    },
    {
      "metadata": {
        "id": "4P5oGTgtpbDy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This tutorial uses the tf.estimator API in TensorFlow to solve a benchmark binary classification problem. Estimators are TensorFlow's most scalable and production-oriented model type. For more information see the Estimator guide."
      ]
    },
    {
      "metadata": {
        "id": "MAqdJVmrphLy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Overview"
      ]
    },
    {
      "metadata": {
        "id": "HJfXQDXZpj4a",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Using census data which contains data a person's age, education, marital status, and occupation (the features), we will try to predict whether or not the person earns more than 50,000 dollars a year (the target label). We will train **a logistic regression model **that, given an individual's information, outputs a number between 0 and 1â€”this can be interpreted as the probability that the individual has an annual income of over 50,000 dollars."
      ]
    },
    {
      "metadata": {
        "id": "99s61MTdp4s6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Set up"
      ]
    },
    {
      "metadata": {
        "id": "RARnn2vgp7B5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Import TensorFlow, feature column support, and supporting modules:"
      ]
    },
    {
      "metadata": {
        "id": "-vwfTyxio64_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.feature_column as fc \n",
        "\n",
        "import os\n",
        "import sys\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hmfjt3i_qI7q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "And let's enable eager execution to inspect this program as we run it:"
      ]
    },
    {
      "metadata": {
        "id": "9Is50QaDqGCa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tf.enable_eager_execution()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M2AcmK_qqgjK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Download the official implementation"
      ]
    },
    {
      "metadata": {
        "id": "2zKaBY5ZqrNC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We'll use the wide and deep model available in TensorFlow's model repository. Download the code, add the root directory to your **Python path**, and jump to the** wide_deep** directory:"
      ]
    },
    {
      "metadata": {
        "id": "JqK8P8h-qMuM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "2993ce6b-e461-436a-ef84-120dbe6f25f2"
      },
      "cell_type": "code",
      "source": [
        "! pip install -q requests\n",
        "! git clone --depth 1 https://github.com/tensorflow/models"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 3028, done.\u001b[K\n",
            "remote: Counting objects: 100% (3028/3028), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2548/2548), done.\u001b[K\n",
            "remote: Total 3028 (delta 532), reused 2047 (delta 403), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (3028/3028), 370.36 MiB | 36.06 MiB/s, done.\n",
            "Resolving deltas: 100% (532/532), done.\n",
            "Checking out files: 100% (2862/2862), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mR6IcVo3sAJh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Add the root directory of the repository to your Python path:"
      ]
    },
    {
      "metadata": {
        "id": "_KK6TRQAsEpa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9d0091ac-3320-4744-db65-063c7e06cbdb"
      },
      "cell_type": "code",
      "source": [
        "os.getcwd()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "kpO0axUDsnka",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "outputId": "5225ea7d-287f-4151-8954-fd074d2de648"
      },
      "cell_type": "code",
      "source": [
        "from pprint import pprint as p\n",
        "p(sys.path)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['',\n",
            " '/env/python',\n",
            " '/usr/lib/python36.zip',\n",
            " '/usr/lib/python3.6',\n",
            " '/usr/lib/python3.6/lib-dynload',\n",
            " '/usr/local/lib/python3.6/dist-packages',\n",
            " '/usr/lib/python3/dist-packages',\n",
            " '/usr/local/lib/python3.6/dist-packages/IPython/extensions',\n",
            " '/root/.ipython']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MKM9gsUhq-FA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eb70aeae-2fba-4a03-9e49-6aad108a81d4"
      },
      "cell_type": "code",
      "source": [
        "models_path = os.path.join(os.getcwd(), 'models')\n",
        "models_path"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/models'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "vklsLlO1sL36",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "e62e6fce-1dba-419b-bc96-e4540d16629f"
      },
      "cell_type": "code",
      "source": [
        "sys.path.append(models_path)\n",
        "p(sys.path)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['',\n",
            " '/env/python',\n",
            " '/usr/lib/python36.zip',\n",
            " '/usr/lib/python3.6',\n",
            " '/usr/lib/python3.6/lib-dynload',\n",
            " '/usr/local/lib/python3.6/dist-packages',\n",
            " '/usr/lib/python3/dist-packages',\n",
            " '/usr/local/lib/python3.6/dist-packages/IPython/extensions',\n",
            " '/root/.ipython',\n",
            " '/content/models']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rzCJPfH6tNp7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Download the dataset:"
      ]
    },
    {
      "metadata": {
        "id": "7_9kpnzEtOiD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from official.wide_deep import census_dataset\n",
        "from official.wide_deep import census_main\n",
        "\n",
        "census_dataset.download(\"/tmp/census_data/\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LIZB_ACEt47D",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Command line usage\n",
        "The repo includes a complete program for experimenting with this type of model.\n",
        "\n",
        "To execute the tutorial code from the command line first add the path to tensorflow/models to your **PYTHONPATH**."
      ]
    },
    {
      "metadata": {
        "id": "n5xDs1f6tQjT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "0e1bc8df-f413-46cd-8178-2c0bf5a9d583"
      },
      "cell_type": "code",
      "source": [
        "p(os.environ)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "environ({'ENV': '/root/.bashrc', 'GCS_READ_CACHE_BLOCK_SIZE_MB': '16', 'CLOUDSDK_CONFIG': '/content/.config', 'CUDA_VERSION': '10.0.130', 'PATH': '/usr/local/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/opt/bin', 'HOME': '/root', 'LD_LIBRARY_PATH': '/usr/local/nvidia/lib:/usr/local/nvidia/lib64', 'LANG': 'en_US.UTF-8', 'SHELL': '/bin/bash', 'LIBRARY_PATH': '/usr/local/cuda/lib64/stubs', 'CUDA_PKG_VERSION': '10-0=10.0.130-1', 'SHLVL': '1', 'NCCL_VERSION': '2.4.2', 'NVIDIA_VISIBLE_DEVICES': 'all', 'TF_FORCE_GPU_ALLOW_GROWTH': 'true', 'DEBIAN_FRONTEND': 'noninteractive', 'CUDNN_VERSION': '7.5.0.56', 'JPY_PARENT_PID': '35', 'PYTHONPATH': '/env/python', 'DATALAB_SETTINGS_OVERRIDES': '{\"kernelManagerProxyPort\":6000,\"kernelManagerProxyHost\":\"172.28.0.3\",\"jupyterArgs\":[\"--ip=\\\\\"172.28.0.2\\\\\"\"]}', 'NO_GCE_CHECK': 'True', 'GLIBCXX_FORCE_NEW': '1', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', '_': '/tools/node/bin/forever', 'LD_PRELOAD': '/usr/lib/x86_64-linux-gnu/libtcmalloc.so.4', 'NVIDIA_REQUIRE_CUDA': 'cuda>=10.0 brand=tesla,driver>=384,driver<385 brand=tesla,driver>=410,driver<411', 'OLDPWD': '/', 'HOSTNAME': 'c25b2890e30a', 'COLAB_GPU': '0', 'PWD': '/', 'GLIBCPP_FORCE_NEW': '1', 'PYTHONWARNINGS': 'ignore:::pip._internal.cli.base_command', 'TERM': 'xterm-color', 'CLICOLOR': '1', 'PAGER': 'cat', 'GIT_PAGER': 'cat', 'MPLBACKEND': 'module://ipykernel.pylab.backend_inline'})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HQxfpAEluBeE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2c9a5e1b-5d62-4f23-f36c-93c8a0690caf"
      },
      "cell_type": "code",
      "source": [
        "os.pathsep"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "':'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "aEo0Bsn9ubKU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#export PYTHONPATH=${PYTHONPATH}:\"$(pwd)/models\"\n",
        "#running from python you need to set the `os.environ` or the subprocess will not see the directory.\n",
        "\n",
        "if \"PYTHONPATH\" in os.environ:\n",
        "  os.environ['PYTHONPATH'] += os.pathsep +  models_path\n",
        "else:\n",
        "  os.environ['PYTHONPATH'] = models_path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FCBW9HCTuw0v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "8b06c928-60f2-4bcd-e5fd-4d3378c147a8"
      },
      "cell_type": "code",
      "source": [
        "os.environ"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "environ({'ENV': '/root/.bashrc', 'GCS_READ_CACHE_BLOCK_SIZE_MB': '16', 'CLOUDSDK_CONFIG': '/content/.config', 'CUDA_VERSION': '10.0.130', 'PATH': '/usr/local/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/opt/bin', 'HOME': '/root', 'LD_LIBRARY_PATH': '/usr/local/nvidia/lib:/usr/local/nvidia/lib64', 'LANG': 'en_US.UTF-8', 'SHELL': '/bin/bash', 'LIBRARY_PATH': '/usr/local/cuda/lib64/stubs', 'CUDA_PKG_VERSION': '10-0=10.0.130-1', 'SHLVL': '1', 'NCCL_VERSION': '2.4.2', 'NVIDIA_VISIBLE_DEVICES': 'all', 'TF_FORCE_GPU_ALLOW_GROWTH': 'true', 'DEBIAN_FRONTEND': 'noninteractive', 'CUDNN_VERSION': '7.5.0.56', 'JPY_PARENT_PID': '35', 'PYTHONPATH': '/env/python:/content/models', 'DATALAB_SETTINGS_OVERRIDES': '{\"kernelManagerProxyPort\":6000,\"kernelManagerProxyHost\":\"172.28.0.3\",\"jupyterArgs\":[\"--ip=\\\\\"172.28.0.2\\\\\"\"]}', 'NO_GCE_CHECK': 'True', 'GLIBCXX_FORCE_NEW': '1', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', '_': '/tools/node/bin/forever', 'LD_PRELOAD': '/usr/lib/x86_64-linux-gnu/libtcmalloc.so.4', 'NVIDIA_REQUIRE_CUDA': 'cuda>=10.0 brand=tesla,driver>=384,driver<385 brand=tesla,driver>=410,driver<411', 'OLDPWD': '/', 'HOSTNAME': 'c25b2890e30a', 'COLAB_GPU': '0', 'PWD': '/', 'GLIBCPP_FORCE_NEW': '1', 'PYTHONWARNINGS': 'ignore:::pip._internal.cli.base_command', 'TERM': 'xterm-color', 'CLICOLOR': '1', 'PAGER': 'cat', 'GIT_PAGER': 'cat', 'MPLBACKEND': 'module://ipykernel.pylab.backend_inline'})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "wbBEHQd_vzZi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Use --help to see what command line options are available:"
      ]
    },
    {
      "metadata": {
        "id": "3xny0J2Ru0Fy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 987
        },
        "outputId": "8c479595-5b80-45ca-c7f2-f164748674e5"
      },
      "cell_type": "code",
      "source": [
        "!python -m official.wide_deep.census_main --help"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-04-13 03:30:57.845387: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2019-04-13 03:30:57.845840: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x19d4840 executing computations on platform Host. Devices:\n",
            "2019-04-13 03:30:57.845918: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "Train DNN on census income dataset.\n",
            "flags:\n",
            "\n",
            "/content/models/official/wide_deep/census_main.py:\n",
            "  -bs,--batch_size:\n",
            "    Batch size for training and evaluation. When using multiple gpus, this is\n",
            "    the\n",
            "    global batch size for all devices. For example, if the batch size is 32 and\n",
            "    there are 4 GPUs, each GPU will get 8 examples on each step.\n",
            "    (default: '40')\n",
            "    (an integer)\n",
            "  --[no]clean:\n",
            "    If set, model_dir will be removed if it exists.\n",
            "    (default: 'false')\n",
            "  -dd,--data_dir:\n",
            "    The location of the input data.\n",
            "    (default: '/tmp/census_data')\n",
            "  --[no]download_if_missing:\n",
            "    Download data to data_dir if it is not already present.\n",
            "    (default: 'true')\n",
            "  -ebe,--epochs_between_evals:\n",
            "    The number of training epochs to run between evaluations.\n",
            "    (default: '2')\n",
            "    (an integer)\n",
            "  -ed,--export_dir:\n",
            "    If set, a SavedModel serialization of the model will be exported to this\n",
            "    directory at the end of training. See the README for more details and\n",
            "    relevant\n",
            "    links.\n",
            "  -hk,--hooks:\n",
            "    A list of (case insensitive) strings to specify the names of training hooks.\n",
            "    ï»¿  Hook:\n",
            "    ï»¿    loggingtensorhook\n",
            "    ï»¿    profilerhook\n",
            "    ï»¿    examplespersecondhook\n",
            "    ï»¿    loggingmetrichook\n",
            "    ï»¿  Example: `--hooks ProfilerHook,ExamplesPerSecondHook`\n",
            "    See official.utils.logs.hooks_helper for details.\n",
            "    (default: 'LoggingTensorHook')\n",
            "    (a comma separated list)\n",
            "  -md,--model_dir:\n",
            "    The location of the model checkpoint files.\n",
            "    (default: '/tmp/census_model')\n",
            "  -mt,--model_type: <wide|deep|wide_deep>: Select model topology.\n",
            "    (default: 'wide_deep')\n",
            "  -te,--train_epochs:\n",
            "    The number of epochs used to train.\n",
            "    (default: '40')\n",
            "    (an integer)\n",
            "\n",
            "Try --helpfull to get a list of all flags.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1pfpNyDFv5-D",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now run the model"
      ]
    },
    {
      "metadata": {
        "id": "ZtCM48rBv9Nz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2166
        },
        "outputId": "e5cd5485-138d-494e-819e-5f99edb8a0f7"
      },
      "cell_type": "code",
      "source": [
        "!python -m official.wide_deep.census_main --model_type=wide --train_epochs=2"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-04-13 03:31:29.640944: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2019-04-13 03:31:29.641238: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x20ce840 executing computations on platform Host. Devices:\n",
            "2019-04-13 03:31:29.641282: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "I0413 03:31:29.645786 139627034961792 estimator.py:201] Using config: {'_model_dir': '/tmp/census_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': device_count {\n",
            "  key: \"GPU\"\n",
            "  value: 0\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7efd4afc1080>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "W0413 03:31:29.647343 139627034961792 tf_logging.py:161] 'cpuinfo' not imported. CPU info will not be logged.\n",
            "I0413 03:31:34.686625 139627034961792 logger.py:152] Benchmark run: {'model_name': 'wide_deep', 'dataset': {'name': 'Census Income'}, 'machine_config': {'gpu_info': {'count': 0}, 'memory_total': 13655322624, 'memory_available': 12509368320}, 'test_id': None, 'run_date': '2019-04-13T03:31:29.646825Z', 'tensorflow_version': {'version': '1.13.1', 'git_hash': \"b'v1.13.1-2-g09e3b09e69'\"}, 'tensorflow_environment_variables': [{'name': 'TF_FORCE_GPU_ALLOW_GROWTH', 'value': 'true'}], 'run_parameters': [{'name': 'batch_size', 'long_value': 40}, {'name': 'model_type', 'string_value': 'wide'}, {'name': 'train_epochs', 'long_value': 2}]}\n",
            "W0413 03:31:34.692189 139627034961792 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "I0413 03:31:34.710671 139627034961792 census_dataset.py:167] Parsing /tmp/census_data/adult.data\n",
            "I0413 03:31:34.753194 139627034961792 estimator.py:1111] Calling model_fn.\n",
            "W0413 03:31:34.810538 139627034961792 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column_v2.py:2703: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "W0413 03:31:34.830144 139627034961792 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column_v2.py:2898: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "I0413 03:31:36.105555 139627034961792 estimator.py:1113] Done calling model_fn.\n",
            "I0413 03:31:36.106000 139627034961792 basic_session_run_hooks.py:527] Create CheckpointSaverHook.\n",
            "I0413 03:31:36.564075 139627034961792 monitored_session.py:222] Graph was finalized.\n",
            "I0413 03:31:36.680933 139627034961792 session_manager.py:491] Running local_init_op.\n",
            "I0413 03:31:36.714919 139627034961792 session_manager.py:493] Done running local_init_op.\n",
            "I0413 03:31:37.614402 139627034961792 basic_session_run_hooks.py:594] Saving checkpoints for 0 into /tmp/census_model/model.ckpt.\n",
            "I0413 03:31:38.499132 139627034961792 basic_session_run_hooks.py:249] average_loss = 0.6931472, loss = 27.725887\n",
            "I0413 03:31:38.499737 139627034961792 basic_session_run_hooks.py:249] loss = 27.725887, step = 1\n",
            "I0413 03:31:39.169050 139627034961792 basic_session_run_hooks.py:680] global_step/sec: 149.2\n",
            "I0413 03:31:39.169867 139627034961792 basic_session_run_hooks.py:247] average_loss = 0.21357986, loss = 8.543195 (0.671 sec)\n",
            "I0413 03:31:39.170199 139627034961792 basic_session_run_hooks.py:247] loss = 8.543195, step = 101 (0.670 sec)\n",
            "I0413 03:31:39.454174 139627034961792 basic_session_run_hooks.py:680] global_step/sec: 350.734\n",
            "I0413 03:31:39.455132 139627034961792 basic_session_run_hooks.py:247] average_loss = 0.5472717, loss = 21.89087 (0.285 sec)\n",
            "I0413 03:31:39.455490 139627034961792 basic_session_run_hooks.py:247] loss = 21.89087, step = 201 (0.285 sec)\n",
            "I0413 03:31:39.758773 139627034961792 basic_session_run_hooks.py:680] global_step/sec: 328.292\n",
            "I0413 03:31:39.759620 139627034961792 basic_session_run_hooks.py:247] average_loss = 0.26180124, loss = 10.47205 (0.304 sec)\n",
            "I0413 03:31:39.759855 139627034961792 basic_session_run_hooks.py:247] loss = 10.47205, step = 301 (0.304 sec)\n",
            "I0413 03:31:40.049250 139627034961792 basic_session_run_hooks.py:680] global_step/sec: 344.294\n",
            "I0413 03:31:40.050042 139627034961792 basic_session_run_hooks.py:247] average_loss = 0.4226365, loss = 16.90546 (0.290 sec)\n",
            "I0413 03:31:40.050319 139627034961792 basic_session_run_hooks.py:247] loss = 16.90546, step = 401 (0.290 sec)\n",
            "I0413 03:31:40.358976 139627034961792 basic_session_run_hooks.py:680] global_step/sec: 322.843\n",
            "I0413 03:31:40.359866 139627034961792 basic_session_run_hooks.py:247] average_loss = 0.3110576, loss = 12.442304 (0.310 sec)\n",
            "I0413 03:31:40.360225 139627034961792 basic_session_run_hooks.py:247] loss = 12.442304, step = 501 (0.310 sec)\n",
            "I0413 03:31:40.642739 139627034961792 basic_session_run_hooks.py:680] global_step/sec: 352.408\n",
            "I0413 03:31:40.643619 139627034961792 basic_session_run_hooks.py:247] average_loss = 0.29333124, loss = 11.73325 (0.284 sec)\n",
            "I0413 03:31:40.643850 139627034961792 basic_session_run_hooks.py:247] loss = 11.73325, step = 601 (0.284 sec)\n",
            "I0413 03:31:40.923756 139627034961792 basic_session_run_hooks.py:680] global_step/sec: 355.841\n",
            "I0413 03:31:40.924611 139627034961792 basic_session_run_hooks.py:247] average_loss = 0.44033003, loss = 17.613201 (0.281 sec)\n",
            "I0413 03:31:40.924839 139627034961792 basic_session_run_hooks.py:247] loss = 17.613201, step = 701 (0.281 sec)\n",
            "I0413 03:31:41.238452 139627034961792 basic_session_run_hooks.py:680] global_step/sec: 317.784\n",
            "I0413 03:31:41.239345 139627034961792 basic_session_run_hooks.py:247] average_loss = 0.38299102, loss = 15.319641 (0.315 sec)\n",
            "I0413 03:31:41.239575 139627034961792 basic_session_run_hooks.py:247] loss = 15.319641, step = 801 (0.315 sec)\n",
            "I0413 03:31:41.602569 139627034961792 basic_session_run_hooks.py:680] global_step/sec: 274.615\n",
            "I0413 03:31:41.603381 139627034961792 basic_session_run_hooks.py:247] average_loss = 0.47921497, loss = 19.168598 (0.364 sec)\n",
            "I0413 03:31:41.603689 139627034961792 basic_session_run_hooks.py:247] loss = 19.168598, step = 901 (0.364 sec)\n",
            "I0413 03:31:41.888976 139627034961792 basic_session_run_hooks.py:680] global_step/sec: 349.178\n",
            "I0413 03:31:41.889860 139627034961792 basic_session_run_hooks.py:247] average_loss = 0.5551871, loss = 22.207485 (0.286 sec)\n",
            "I0413 03:31:41.890214 139627034961792 basic_session_run_hooks.py:247] loss = 22.207485, step = 1001 (0.287 sec)\n",
            "I0413 03:31:42.193089 139627034961792 basic_session_run_hooks.py:680] global_step/sec: 328.813\n",
            "I0413 03:31:42.194015 139627034961792 basic_session_run_hooks.py:247] average_loss = 0.4912855, loss = 19.65142 (0.304 sec)\n",
            "I0413 03:31:42.194249 139627034961792 basic_session_run_hooks.py:247] loss = 19.65142, step = 1101 (0.304 sec)\n",
            "I0413 03:31:42.490359 139627034961792 basic_session_run_hooks.py:680] global_step/sec: 336.388\n",
            "I0413 03:31:42.491204 139627034961792 basic_session_run_hooks.py:247] average_loss = 0.42473063, loss = 16.989225 (0.297 sec)\n",
            "I0413 03:31:42.491429 139627034961792 basic_session_run_hooks.py:247] loss = 16.989225, step = 1201 (0.297 sec)\n",
            "I0413 03:31:42.779433 139627034961792 basic_session_run_hooks.py:680] global_step/sec: 345.929\n",
            "I0413 03:31:42.780231 139627034961792 basic_session_run_hooks.py:247] average_loss = 0.2786266, loss = 11.145063 (0.289 sec)\n",
            "I0413 03:31:42.780542 139627034961792 basic_session_run_hooks.py:247] loss = 11.145063, step = 1301 (0.289 sec)\n",
            "I0413 03:31:43.085368 139627034961792 basic_session_run_hooks.py:680] global_step/sec: 326.878\n",
            "I0413 03:31:43.086135 139627034961792 basic_session_run_hooks.py:247] average_loss = 0.46168822, loss = 18.46753 (0.306 sec)\n",
            "I0413 03:31:43.086363 139627034961792 basic_session_run_hooks.py:247] loss = 18.46753, step = 1401 (0.306 sec)\n",
            "I0413 03:31:43.394566 139627034961792 basic_session_run_hooks.py:680] global_step/sec: 323.421\n",
            "I0413 03:31:43.395454 139627034961792 basic_session_run_hooks.py:247] average_loss = 0.26146272, loss = 10.4585085 (0.309 sec)\n",
            "I0413 03:31:43.395793 139627034961792 basic_session_run_hooks.py:247] loss = 10.4585085, step = 1501 (0.309 sec)\n",
            "I0413 03:31:43.680366 139627034961792 basic_session_run_hooks.py:680] global_step/sec: 349.885\n",
            "I0413 03:31:43.681097 139627034961792 basic_session_run_hooks.py:247] average_loss = 0.3261792, loss = 13.047169 (0.286 sec)\n",
            "I0413 03:31:43.681331 139627034961792 basic_session_run_hooks.py:247] loss = 13.047169, step = 1601 (0.286 sec)\n",
            "I0413 03:31:43.788516 139627034961792 basic_session_run_hooks.py:594] Saving checkpoints for 1629 into /tmp/census_model/model.ckpt.\n",
            "I0413 03:31:43.994742 139627034961792 estimator.py:359] Loss for final step: 0.25378293.\n",
            "I0413 03:31:44.006508 139627034961792 census_dataset.py:167] Parsing /tmp/census_data/adult.test\n",
            "I0413 03:31:44.036221 139627034961792 estimator.py:1111] Calling model_fn.\n",
            "W0413 03:31:45.155488 139627034961792 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/metrics_impl.py:2002: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "W0413 03:31:45.597332 139627034961792 metrics_impl.py:783] Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
            "W0413 03:31:45.621616 139627034961792 metrics_impl.py:783] Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
            "I0413 03:31:45.645008 139627034961792 estimator.py:1113] Done calling model_fn.\n",
            "I0413 03:31:45.668194 139627034961792 evaluation.py:257] Starting evaluation at 2019-04-13T03:31:45Z\n",
            "I0413 03:31:45.949693 139627034961792 monitored_session.py:222] Graph was finalized.\n",
            "W0413 03:31:45.950315 139627034961792 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "I0413 03:31:45.951754 139627034961792 saver.py:1270] Restoring parameters from /tmp/census_model/model.ckpt-1629\n",
            "I0413 03:31:46.088609 139627034961792 session_manager.py:491] Running local_init_op.\n",
            "I0413 03:31:46.142767 139627034961792 session_manager.py:493] Done running local_init_op.\n",
            "I0413 03:31:48.104316 139627034961792 evaluation.py:277] Finished evaluation at 2019-04-13-03:31:48\n",
            "I0413 03:31:48.104654 139627034961792 estimator.py:1979] Saving dict for global step 1629: accuracy = 0.8346539, accuracy_baseline = 0.76377374, auc = 0.8841605, auc_precision_recall = 0.69556266, average_loss = 0.3515969, global_step = 1629, label/mean = 0.23622628, loss = 14.030268, precision = 0.70681006, prediction/mean = 0.2227363, recall = 0.5127405\n",
            "I0413 03:31:48.465301 139627034961792 estimator.py:2039] Saving 'checkpoint_path' summary for global step 1629: /tmp/census_model/model.ckpt-1629\n",
            "I0413 03:31:48.466077 139627034961792 wide_deep_run_loop.py:116] Results at epoch 2 / 2\n",
            "I0413 03:31:48.466235 139627034961792 wide_deep_run_loop.py:117] ------------------------------------------------------------\n",
            "I0413 03:31:48.466316 139627034961792 wide_deep_run_loop.py:120] accuracy: 0.8346539\n",
            "I0413 03:31:48.466378 139627034961792 wide_deep_run_loop.py:120] accuracy_baseline: 0.76377374\n",
            "I0413 03:31:48.466437 139627034961792 wide_deep_run_loop.py:120] auc: 0.8841605\n",
            "I0413 03:31:48.466493 139627034961792 wide_deep_run_loop.py:120] auc_precision_recall: 0.69556266\n",
            "I0413 03:31:48.466549 139627034961792 wide_deep_run_loop.py:120] average_loss: 0.3515969\n",
            "I0413 03:31:48.466612 139627034961792 wide_deep_run_loop.py:120] global_step: 1629\n",
            "I0413 03:31:48.466666 139627034961792 wide_deep_run_loop.py:120] label/mean: 0.23622628\n",
            "I0413 03:31:48.466721 139627034961792 wide_deep_run_loop.py:120] loss: 14.030268\n",
            "I0413 03:31:48.466774 139627034961792 wide_deep_run_loop.py:120] precision: 0.70681006\n",
            "I0413 03:31:48.466844 139627034961792 wide_deep_run_loop.py:120] prediction/mean: 0.2227363\n",
            "I0413 03:31:48.466900 139627034961792 wide_deep_run_loop.py:120] recall: 0.5127405\n",
            "I0413 03:31:48.467059 139627034961792 logger.py:147] Benchmark metric: {'name': 'accuracy', 'value': 0.834653913974762, 'unit': None, 'global_step': 1629, 'timestamp': '2019-04-13T03:31:48.467017Z', 'extras': []}\n",
            "I0413 03:31:48.467186 139627034961792 logger.py:147] Benchmark metric: {'name': 'accuracy_baseline', 'value': 0.7637737393379211, 'unit': None, 'global_step': 1629, 'timestamp': '2019-04-13T03:31:48.467169Z', 'extras': []}\n",
            "I0413 03:31:48.467283 139627034961792 logger.py:147] Benchmark metric: {'name': 'auc', 'value': 0.8841605186462402, 'unit': None, 'global_step': 1629, 'timestamp': '2019-04-13T03:31:48.467266Z', 'extras': []}\n",
            "I0413 03:31:48.467365 139627034961792 logger.py:147] Benchmark metric: {'name': 'auc_precision_recall', 'value': 0.6955626606941223, 'unit': None, 'global_step': 1629, 'timestamp': '2019-04-13T03:31:48.467350Z', 'extras': []}\n",
            "I0413 03:31:48.467447 139627034961792 logger.py:147] Benchmark metric: {'name': 'average_loss', 'value': 0.3515968918800354, 'unit': None, 'global_step': 1629, 'timestamp': '2019-04-13T03:31:48.467432Z', 'extras': []}\n",
            "I0413 03:31:48.467526 139627034961792 logger.py:147] Benchmark metric: {'name': 'label/mean', 'value': 0.23622627556324005, 'unit': None, 'global_step': 1629, 'timestamp': '2019-04-13T03:31:48.467512Z', 'extras': []}\n",
            "I0413 03:31:48.467603 139627034961792 logger.py:147] Benchmark metric: {'name': 'loss', 'value': 14.030267715454102, 'unit': None, 'global_step': 1629, 'timestamp': '2019-04-13T03:31:48.467589Z', 'extras': []}\n",
            "I0413 03:31:48.467679 139627034961792 logger.py:147] Benchmark metric: {'name': 'precision', 'value': 0.7068100571632385, 'unit': None, 'global_step': 1629, 'timestamp': '2019-04-13T03:31:48.467666Z', 'extras': []}\n",
            "I0413 03:31:48.467757 139627034961792 logger.py:147] Benchmark metric: {'name': 'prediction/mean', 'value': 0.22273629903793335, 'unit': None, 'global_step': 1629, 'timestamp': '2019-04-13T03:31:48.467743Z', 'extras': []}\n",
            "I0413 03:31:48.467859 139627034961792 logger.py:147] Benchmark metric: {'name': 'recall', 'value': 0.5127404928207397, 'unit': None, 'global_step': 1629, 'timestamp': '2019-04-13T03:31:48.467845Z', 'extras': []}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rCqZywOcwM4j",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Read the US Census Data"
      ]
    },
    {
      "metadata": {
        "id": "JxrFjMLwwnJL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This example uses the U.S Census Income Dataset from 1994 and 1995. We have provided the census_dataset.py script to download the data and perform a little cleanup.\n",
        "\n",
        "Since the task is a binary classification problem, we'll construct a label column named \"label\" whose value is 1 if the income is over 50K, and 0 otherwise. For reference, see the input_fn in census_main.py.\n",
        "\n",
        "Let's look at the data to see which columns we can use to predict the target label:"
      ]
    },
    {
      "metadata": {
        "id": "aAOWjc2dwW4v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "797687c9-e4c4-4ede-d259-c55d0b9d3cd2"
      },
      "cell_type": "code",
      "source": [
        "!ls  /tmp/census_data/"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "adult.data  adult.test\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bWqDYF1CwuEP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_file = \"/tmp/census_data/adult.data\"\n",
        "test_file = \"/tmp/census_data/adult.test\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XKCPeHTTw7IK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "pandas provides some convenient utilities for data analysis. Here's a list of columns available in the Census Income dataset:"
      ]
    },
    {
      "metadata": {
        "id": "eyhDr5eaw4iT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        },
        "outputId": "58518f9f-ec75-4fca-c5ad-7b30934304c9"
      },
      "cell_type": "code",
      "source": [
        "import pandas\n",
        "\n",
        "train_df = pandas.read_csv(train_file, header = None, names = census_dataset._CSV_COLUMNS)\n",
        "test_df = pandas.read_csv(test_file, header = None, names = census_dataset._CSV_COLUMNS)\n",
        "\n",
        "train_df.head()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>workclass</th>\n",
              "      <th>fnlwgt</th>\n",
              "      <th>education</th>\n",
              "      <th>education_num</th>\n",
              "      <th>marital_status</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>gender</th>\n",
              "      <th>capital_gain</th>\n",
              "      <th>capital_loss</th>\n",
              "      <th>hours_per_week</th>\n",
              "      <th>native_country</th>\n",
              "      <th>income_bracket</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>39</td>\n",
              "      <td>State-gov</td>\n",
              "      <td>77516</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Adm-clerical</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>2174</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>50</td>\n",
              "      <td>Self-emp-not-inc</td>\n",
              "      <td>83311</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Exec-managerial</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>38</td>\n",
              "      <td>Private</td>\n",
              "      <td>215646</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Divorced</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>53</td>\n",
              "      <td>Private</td>\n",
              "      <td>234721</td>\n",
              "      <td>11th</td>\n",
              "      <td>7</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Husband</td>\n",
              "      <td>Black</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>28</td>\n",
              "      <td>Private</td>\n",
              "      <td>338409</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>Wife</td>\n",
              "      <td>Black</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>Cuba</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age         workclass  fnlwgt  education  education_num  \\\n",
              "0   39         State-gov   77516  Bachelors             13   \n",
              "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
              "2   38           Private  215646    HS-grad              9   \n",
              "3   53           Private  234721       11th              7   \n",
              "4   28           Private  338409  Bachelors             13   \n",
              "\n",
              "       marital_status         occupation   relationship   race  gender  \\\n",
              "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
              "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
              "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
              "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
              "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
              "\n",
              "   capital_gain  capital_loss  hours_per_week native_country income_bracket  \n",
              "0          2174             0              40  United-States          <=50K  \n",
              "1             0             0              13  United-States          <=50K  \n",
              "2             0             0              40  United-States          <=50K  \n",
              "3             0             0              40  United-States          <=50K  \n",
              "4             0             0              40           Cuba          <=50K  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "HJfsZuAUxPOq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The columns are grouped into two types: categorical and continuous columns:\n",
        "\n",
        "* A column is called categorical if its value can only be one of the categories in a finite set. For example, the relationship status of a person (wife, husband, unmarried, etc.) or the education level (high school, college, etc.) are categorical columns.\n",
        "\n",
        "* A column is called continuous if its value can be any numerical value in a continuous range. For example, the capital gain of a person (e.g. $14,084) is a continuous column."
      ]
    },
    {
      "metadata": {
        "id": "t5fwuWztxf86",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Converting Data into Tensors"
      ]
    },
    {
      "metadata": {
        "id": "exBv4Is3xkhL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "When building a **tf.estimator** model, the input data is specified by using an **input function** (or input_fn). This builder function returns a **tf.data.Datase**t of batches of (features-dict, label) pairs. It is not called until it is passed to tf.estimator.Estimator methods such as train and evaluate.\n",
        "\n",
        "The input builder function returns the following pair:\n",
        "\n",
        "* **features**: A dict from feature names to Tensors or SparseTensors containing batches of features.\n",
        "* **labels**: A Tensor containing batches of labels.\n",
        "\n",
        "The keys of the features are used to configure the model's input layer."
      ]
    },
    {
      "metadata": {
        "id": "ZAT1RN9ByHi5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Note: The input function is called while constructing the TensorFlow graph, not while running the graph. It is returning a representation of the input data as a sequence of TensorFlow graph operations."
      ]
    },
    {
      "metadata": {
        "id": "Ned47mkcyMzh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "For small problems like this, it's easy to make a tf.data.Dataset by slicing the pandas.DataFrame:"
      ]
    },
    {
      "metadata": {
        "id": "MoGpSlEZxWPx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def easy_input_function(df, label_key, num_epochs, shuffle, batch_size):\n",
        "  label = df[label_key]\n",
        "  ds = tf.data.Dataset.from_tensor_slices((dict(df),label))\n",
        "\n",
        "  if shuffle:\n",
        "    ds = ds.shuffle(10000)\n",
        "\n",
        "  ds = ds.batch(batch_size).repeat(num_epochs)\n",
        "\n",
        "  return ds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_tWPgiysyisb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Since we have eager execution enabled, it's easy to inspect the resulting dataset:"
      ]
    },
    {
      "metadata": {
        "id": "fckLSEHHydFV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "77cc48ac-1826-4924-a363-8eae7906d034"
      },
      "cell_type": "code",
      "source": [
        "ds = easy_input_function(train_df, label_key='income_bracket', num_epochs=5, shuffle=True, batch_size=10)\n",
        "ds"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<DatasetV1Adapter shapes: ({age: (?,), workclass: (?,), fnlwgt: (?,), education: (?,), education_num: (?,), marital_status: (?,), occupation: (?,), relationship: (?,), race: (?,), gender: (?,), capital_gain: (?,), capital_loss: (?,), hours_per_week: (?,), native_country: (?,), income_bracket: (?,)}, (?,)), types: ({age: tf.int32, workclass: tf.string, fnlwgt: tf.int32, education: tf.string, education_num: tf.int32, marital_status: tf.string, occupation: tf.string, relationship: tf.string, race: tf.string, gender: tf.string, capital_gain: tf.int32, capital_loss: tf.int32, hours_per_week: tf.int32, native_country: tf.string, income_bracket: tf.string}, tf.string)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "Am2Gx_AWzSAj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "81d2fca6-7d36-4ac8-8cd8-ba3d50f22f74"
      },
      "cell_type": "code",
      "source": [
        "for feature_batch, label_batch in ds.take(1):\n",
        "  print('Some feature keys:', list(feature_batch.keys())[:5])\n",
        "  print()\n",
        "  print('A batch of Ages  :', feature_batch['age'])\n",
        "  print()\n",
        "  print('A batch of Labels:', label_batch )"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some feature keys: ['age', 'workclass', 'fnlwgt', 'education', 'education_num']\n",
            "\n",
            "A batch of Ages  : tf.Tensor([30 52 29 19 26 49 49 35 54 33], shape=(10,), dtype=int32)\n",
            "\n",
            "A batch of Labels: tf.Tensor(\n",
            "[b'<=50K' b'<=50K' b'<=50K' b'<=50K' b'<=50K' b'<=50K' b'>50K' b'<=50K'\n",
            " b'<=50K' b'>50K'], shape=(10,), dtype=string)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aeAsHUWO0hgy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "But this approach has severly-limited scalability. Larger datasets should be streamed from disk. The census_dataset.input_fn provides an example of how to do this using tf.decode_csv and tf.data.TextLineDataset:"
      ]
    },
    {
      "metadata": {
        "id": "-5YtZTkozK0j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "outputId": "4ab5499f-36c8-4ddc-c0a5-7c10449d4049"
      },
      "cell_type": "code",
      "source": [
        "import inspect\n",
        "print(inspect.getsource(census_dataset.input_fn))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "def input_fn(data_file, num_epochs, shuffle, batch_size):\n",
            "  \"\"\"Generate an input function for the Estimator.\"\"\"\n",
            "  assert tf.gfile.Exists(data_file), (\n",
            "      '%s not found. Please make sure you have run census_dataset.py and '\n",
            "      'set the --data_dir argument to the correct path.' % data_file)\n",
            "\n",
            "  def parse_csv(value):\n",
            "    tf.logging.info('Parsing {}'.format(data_file))\n",
            "    columns = tf.decode_csv(value, record_defaults=_CSV_COLUMN_DEFAULTS)\n",
            "    features = dict(zip(_CSV_COLUMNS, columns))\n",
            "    labels = features.pop('income_bracket')\n",
            "    classes = tf.equal(labels, '>50K')  # binary classification\n",
            "    return features, classes\n",
            "\n",
            "  # Extract lines from input files using the Dataset API.\n",
            "  dataset = tf.data.TextLineDataset(data_file)\n",
            "\n",
            "  if shuffle:\n",
            "    dataset = dataset.shuffle(buffer_size=_NUM_EXAMPLES['train'])\n",
            "\n",
            "  dataset = dataset.map(parse_csv, num_parallel_calls=5)\n",
            "\n",
            "  # We call repeat after shuffling, rather than before, to prevent separate\n",
            "  # epochs from blending together.\n",
            "  dataset = dataset.repeat(num_epochs)\n",
            "  dataset = dataset.batch(batch_size)\n",
            "  return dataset\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "o8EbsaVO2Vyz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This input_fn returns equivalent output:"
      ]
    },
    {
      "metadata": {
        "id": "y07CvTKS2JU7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "acc33445-f473-4a93-f765-2ce9b831d129"
      },
      "cell_type": "code",
      "source": [
        "ds = census_dataset.input_fn(train_file, num_epochs=5, shuffle=True, batch_size=10)\n",
        "\n",
        "for feature_batch, label_batch in ds.take(1):\n",
        "  print('Feature keys:', list(feature_batch.keys())[:5])\n",
        "  print()\n",
        "  print('Age batch   :', feature_batch['age'])\n",
        "  print()\n",
        "  print('Label batch :', label_batch )"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Parsing /tmp/census_data/adult.data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0413 03:59:29.075873 140372419536768 census_dataset.py:167] Parsing /tmp/census_data/adult.data\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Feature keys: ['age', 'workclass', 'fnlwgt', 'education', 'education_num']\n",
            "\n",
            "Age batch   : tf.Tensor([23 20 42 36 34 33 28 52 42 28], shape=(10,), dtype=int32)\n",
            "\n",
            "Label batch : tf.Tensor([False False False False False False  True False False  True], shape=(10,), dtype=bool)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RDJV0IHn2hYp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Because **Estimators** expect an **input_fn** that takes no arguments, we typically wrap configurable input function into an obejct with the expected signature. For this notebook configure the **train_inpf** to iterate over the data twice:"
      ]
    },
    {
      "metadata": {
        "id": "7l-p3huc2ago",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import functools\n",
        "\n",
        "train_inpf = functools.partial(census_dataset.input_fn, train_file, num_epochs=2, shuffle=True, batch_size=64)\n",
        "test_inpf = functools.partial(census_dataset.input_fn, test_file, num_epochs=1, shuffle=False, batch_size=64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uuJSJEAk4Q-i",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Selecting and Engineering Features for the Model"
      ]
    },
    {
      "metadata": {
        "id": "D19-uk9f4VjF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Estimators use a system called **feature columns** to describe how the model should interpret each of the raw input features. \n",
        "An Estimator expects a vector of **numeric inputs**, and **feature columns describe how the model should convert each feature**.\n",
        "\n",
        "Selecting and crafting the right set of feature columns is key to learning an effective model. A feature column can be either one of the raw inputs in the original features dict (**a base feature column**), or any new columns created using transformations defined over one or multiple base columns (**a derived feature columns**).\n",
        "\n",
        "A feature column is an abstract concept of any raw or derived variable that can be used to predict the target label."
      ]
    },
    {
      "metadata": {
        "id": "ucXHMxSJIAsx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Base Feature Columns"
      ]
    },
    {
      "metadata": {
        "id": "iI3Foj_CIEcB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Numeric Columns\n",
        "\n",
        "The simplest **feature_column** is **numeric_column**. This indicates that a feature is a numeric value that should be input to the model directly. For example:"
      ]
    },
    {
      "metadata": {
        "id": "rWd50FWw4TpH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "age = fc.numeric_column('age')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pbgGajeEIfu7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The model will use the **feature_column** definitions to build the model input. You can inspect the resulting output using the **input_layer** function:"
      ]
    },
    {
      "metadata": {
        "id": "72Ke8PzAIaTB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        },
        "outputId": "00d9902e-053d-4767-b857-14433e7f52a1"
      },
      "cell_type": "code",
      "source": [
        "fc.input_layer(feature_batch, [age]).numpy()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column.py:205: NumericColumn._get_dense_tensor (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0413 05:19:53.518070 140372419536768 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column.py:205: NumericColumn._get_dense_tensor (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column.py:2121: NumericColumn._transform_feature (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0413 05:19:53.521773 140372419536768 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column.py:2121: NumericColumn._transform_feature (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column_v2.py:2703: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0413 05:19:53.526350 140372419536768 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column_v2.py:2703: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column.py:206: NumericColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0413 05:19:53.530299 140372419536768 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column.py:206: NumericColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[23.],\n",
              "       [20.],\n",
              "       [42.],\n",
              "       [36.],\n",
              "       [34.],\n",
              "       [33.],\n",
              "       [28.],\n",
              "       [52.],\n",
              "       [42.],\n",
              "       [28.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "metadata": {
        "id": "mV30l6AiI55D",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The following will train and evaluate a model using only the **age** feature:"
      ]
    },
    {
      "metadata": {
        "id": "1KZ5NlDeI0L_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "f52f33f0-d88c-4c12-9036-2e145118b848"
      },
      "cell_type": "code",
      "source": [
        "classifier = tf.estimator.LinearClassifier(feature_columns=[age])\n",
        "classifier.train(train_inpf)\n",
        "result = classifier.evaluate(test_inpf)\n",
        "\n",
        "clear_output()  # used for display in notebook\n",
        "print(result)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'accuracy': 0.76352805, 'accuracy_baseline': 0.76377374, 'auc': 0.6782331, 'auc_precision_recall': 0.31136113, 'average_loss': 0.52553695, 'label/mean': 0.23622628, 'loss': 33.55399, 'precision': 0.35714287, 'prediction/mean': 0.2145834, 'recall': 0.001300052, 'global_step': 1018}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iGA0X3r1Jcej",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Similarly, we can define a **NumericColumn** for each continuous feature column that we want to use in the model:"
      ]
    },
    {
      "metadata": {
        "id": "34yFckc5JLzz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "outputId": "c27d97ac-4225-489b-ad9b-ba8143fd5151"
      },
      "cell_type": "code",
      "source": [
        "education_num = tf.feature_column.numeric_column('education_num')\n",
        "capital_gain = tf.feature_column.numeric_column('capital_gain')\n",
        "capital_loss = tf.feature_column.numeric_column('capital_loss')\n",
        "hours_per_week = tf.feature_column.numeric_column('hours_per_week')\n",
        "\n",
        "my_numeric_columns = [age,education_num, capital_gain, capital_loss, hours_per_week]\n",
        "\n",
        "fc.input_layer(feature_batch, my_numeric_columns).numpy()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.300e+01, 0.000e+00, 0.000e+00, 9.000e+00, 4.000e+01],\n",
              "       [2.000e+01, 0.000e+00, 0.000e+00, 1.000e+01, 2.500e+01],\n",
              "       [4.200e+01, 0.000e+00, 0.000e+00, 4.000e+00, 4.000e+01],\n",
              "       [3.600e+01, 0.000e+00, 0.000e+00, 3.000e+00, 4.000e+01],\n",
              "       [3.400e+01, 0.000e+00, 0.000e+00, 1.000e+01, 4.500e+01],\n",
              "       [3.300e+01, 0.000e+00, 0.000e+00, 1.300e+01, 4.000e+01],\n",
              "       [2.800e+01, 8.614e+03, 0.000e+00, 1.300e+01, 4.000e+01],\n",
              "       [5.200e+01, 0.000e+00, 0.000e+00, 1.000e+01, 4.000e+01],\n",
              "       [4.200e+01, 0.000e+00, 0.000e+00, 9.000e+00, 5.000e+01],\n",
              "       [2.800e+01, 0.000e+00, 0.000e+00, 7.000e+00, 5.000e+01]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "ckbIf8OPJoJh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "You could retrain a model on these features by changing the `feature_columns` argument to the constructor:"
      ]
    },
    {
      "metadata": {
        "id": "yo71vmubJjnT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "outputId": "89a5262f-8bc2-4e55-be2e-120a34d18380"
      },
      "cell_type": "code",
      "source": [
        "classifier = tf.estimator.LinearClassifier(feature_columns=my_numeric_columns)\n",
        "classifier.train(train_inpf)\n",
        "\n",
        "result = classifier.evaluate(test_inpf)\n",
        "\n",
        "clear_output()\n",
        "\n",
        "for key,value in sorted(result.items()):\n",
        "  print('%s: %s' % (key, value))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 0.7826301\n",
            "accuracy_baseline: 0.76377374\n",
            "auc: 0.59648025\n",
            "auc_precision_recall: 0.4188821\n",
            "average_loss: 1.6398073\n",
            "global_step: 1018\n",
            "label/mean: 0.23622628\n",
            "loss: 104.69688\n",
            "precision: 0.61619985\n",
            "prediction/mean: 0.1797892\n",
            "recall: 0.21164846\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gGUAeH2RKCir",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Categorical Columns"
      ]
    },
    {
      "metadata": {
        "id": "_M9-Woi9KJBs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "To define a feature column for a categorical feature, create a `CategoricalColumn` using one of the `tf.feature_column.categorical_column`* functions.\n",
        "\n",
        "If you know the set of all possible feature values of a columnâ€”and there are only a few of themâ€”use `categorical_column_with_vocabulary_list. `Each key in the list is assigned an auto-incremented ID starting from 0. For example, for the relationship column we can assign the feature string Husband to an integer ID of 0 and \"Not-in-family\" to 1, etc."
      ]
    },
    {
      "metadata": {
        "id": "ezId14UuJw7y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "relationship = fc.categorical_column_with_vocabulary_list(\n",
        "    'relationship',\n",
        "    ['Husband', 'Not-in-family', 'Wife', 'Own-child', 'Unmarried', 'Other-relative'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "guj6EaFpKYqS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This creates a` sparse one-hot vector` from the raw input feature.\n",
        "\n",
        "The input_layer function we're using is designed for DNN models and expects `dense inputs`. To demonstrate the categorical column we must wrap it in a `tf.feature_column.indicator_column` to create the `dense one-hot output` (Linear Estimators can often skip this dense-step)."
      ]
    },
    {
      "metadata": {
        "id": "ASINnuShKsVi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Run the input layer, configured with both the age and relationship columns:"
      ]
    },
    {
      "metadata": {
        "id": "8iqvaCREKVa8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 970
        },
        "outputId": "4eece052-fc29-4dcb-c309-0a66091a6272"
      },
      "cell_type": "code",
      "source": [
        "fc.input_layer(feature_batch, [age, fc.indicator_column(relationship)])"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column.py:205: IndicatorColumn._get_dense_tensor (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0413 05:28:20.790768 140372419536768 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column.py:205: IndicatorColumn._get_dense_tensor (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column.py:2121: IndicatorColumn._transform_feature (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0413 05:28:20.799090 140372419536768 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column.py:2121: IndicatorColumn._transform_feature (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column_v2.py:4295: VocabularyListCategoricalColumn._get_sparse_tensors (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0413 05:28:20.801094 140372419536768 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column_v2.py:4295: VocabularyListCategoricalColumn._get_sparse_tensors (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column.py:2121: VocabularyListCategoricalColumn._transform_feature (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0413 05:28:20.803270 140372419536768 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column.py:2121: VocabularyListCategoricalColumn._transform_feature (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/lookup_ops.py:1137: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0413 05:28:20.807149 140372419536768 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/lookup_ops.py:1137: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column_v2.py:4266: IndicatorColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0413 05:28:20.815212 140372419536768 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column_v2.py:4266: IndicatorColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column_v2.py:4321: VocabularyListCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0413 05:28:20.818351 140372419536768 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column_v2.py:4321: VocabularyListCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=4917, shape=(10, 7), dtype=float32, numpy=\n",
              "array([[23.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
              "       [20.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
              "       [42.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
              "       [36.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
              "       [34.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
              "       [33.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
              "       [28.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
              "       [52.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
              "       [42.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
              "       [28.,  1.,  0.,  0.,  0.,  0.,  0.]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "metadata": {
        "id": "v_u17nwQK6hK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "If we don't know the set of possible values in advance, use the categorical_column_with_hash_bucket instead:"
      ]
    },
    {
      "metadata": {
        "id": "HfelyA3mKwCK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "occupation = tf.feature_column.categorical_column_with_hash_bucket(\n",
        "    'occupation', hash_bucket_size=1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RglNUnKmLE-D",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Here, each possible value in the feature column occupation is hashed to an integer ID as we encounter them in training. The example batch has a few different occupations:"
      ]
    },
    {
      "metadata": {
        "id": "fJCvLHpaK9aN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "07e2a2f0-2902-47ea-9742-3dbf9aa5b343"
      },
      "cell_type": "code",
      "source": [
        "for item in feature_batch['occupation'].numpy():\n",
        "    print(item.decode())"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Machine-op-inspct\n",
            "Protective-serv\n",
            "Transport-moving\n",
            "Machine-op-inspct\n",
            "Exec-managerial\n",
            "Adm-clerical\n",
            "Sales\n",
            "Craft-repair\n",
            "Craft-repair\n",
            "Craft-repair\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "s7YbWTMVLosS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "If we run **input_layer** with the hashed column, we see that the output shape is (batch_size, hash_bucket_size):"
      ]
    },
    {
      "metadata": {
        "id": "MCxJcJ2NLrAW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "outputId": "74efa1b4-3737-4147-9136-64cef4ea532e"
      },
      "cell_type": "code",
      "source": [
        "occupation_result = fc.input_layer(feature_batch, [fc.indicator_column(occupation)])\n",
        "\n",
        "occupation_result.numpy().shape"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column_v2.py:4295: HashedCategoricalColumn._get_sparse_tensors (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0413 05:32:30.652940 140372419536768 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column_v2.py:4295: HashedCategoricalColumn._get_sparse_tensors (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column.py:2121: HashedCategoricalColumn._transform_feature (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0413 05:32:30.656516 140372419536768 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column.py:2121: HashedCategoricalColumn._transform_feature (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column_v2.py:4321: HashedCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0413 05:32:30.659944 140372419536768 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column_v2.py:4321: HashedCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 1000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "metadata": {
        "id": "Zyr8OyPvLuby",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "It's easier to see the actual results if we take the tf.argmax over the **hash_bucket_size** dimension. Notice how any duplicate occupations are mapped to the same pseudo-random index:"
      ]
    },
    {
      "metadata": {
        "id": "F_vpwBv9LzLG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7683f9b0-7d78-4ec0-ed8e-51b6fe4fce56"
      },
      "cell_type": "code",
      "source": [
        "tf.argmax(occupation_result, axis=1).numpy()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([911, 684, 420, 911, 800,  96, 631, 466, 466, 466])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "metadata": {
        "id": "3jreA7wHL4OD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "No matter how we choose to define a **SparseColumn**, each feature string is mapped into an integer ID by looking up **a fixed mapping** or by **hashing**. Under the hood, the LinearModel class is responsible for managing the mapping and creating **tf.Variable** to store the model parameters (model weights) for each feature ID. The model parameters are learned through the model training process described later.\n",
        "\n",
        "Let's do the similar trick to define the other categorical features:"
      ]
    },
    {
      "metadata": {
        "id": "KKO8TvOBL068",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "education = tf.feature_column.categorical_column_with_vocabulary_list(\n",
        "    'education', [\n",
        "        'Bachelors', 'HS-grad', '11th', 'Masters', '9th', 'Some-college',\n",
        "        'Assoc-acdm', 'Assoc-voc', '7th-8th', 'Doctorate', 'Prof-school',\n",
        "        '5th-6th', '10th', '1st-4th', 'Preschool', '12th'])\n",
        "\n",
        "marital_status = tf.feature_column.categorical_column_with_vocabulary_list(\n",
        "    'marital_status', [\n",
        "        'Married-civ-spouse', 'Divorced', 'Married-spouse-absent',\n",
        "        'Never-married', 'Separated', 'Married-AF-spouse', 'Widowed'])\n",
        "\n",
        "workclass = tf.feature_column.categorical_column_with_vocabulary_list(\n",
        "    'workclass', [\n",
        "        'Self-emp-not-inc', 'Private', 'State-gov', 'Federal-gov',\n",
        "        'Local-gov', '?', 'Self-emp-inc', 'Without-pay', 'Never-worked'])\n",
        "\n",
        "\n",
        "my_categorical_columns = [relationship, occupation, education, marital_status, workclass]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7D_Tv-aiMNla",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "It's easy to use both sets of columns to configure a model that uses all these features:\n"
      ]
    },
    {
      "metadata": {
        "id": "ZCijtJ4fMQQU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "outputId": "00b4ea11-07b7-4d5c-b6ca-105eec526bf8"
      },
      "cell_type": "code",
      "source": [
        "classifier = tf.estimator.LinearClassifier(feature_columns=my_numeric_columns+my_categorical_columns)\n",
        "classifier.train(train_inpf)\n",
        "result = classifier.evaluate(test_inpf)\n",
        "\n",
        "clear_output()\n",
        "\n",
        "for key,value in sorted(result.items()):\n",
        "  print('%s: %s' % (key, value))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 0.84865797\n",
            "accuracy_baseline: 0.76377374\n",
            "auc: 0.89755017\n",
            "auc_precision_recall: 0.74972826\n",
            "average_loss: 0.35013643\n",
            "global_step: 1018\n",
            "label/mean: 0.23622628\n",
            "loss: 22.35518\n",
            "precision: 0.7473157\n",
            "prediction/mean: 0.19968465\n",
            "recall: 0.5429017\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pDeLiQyIMv2a",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Derived feature columns"
      ]
    },
    {
      "metadata": {
        "id": "sv7Xuu12NAoi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Make Continuous Features Categorical through Bucketization**"
      ]
    },
    {
      "metadata": {
        "id": "QLaAMDTmNa8t",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Sometimes the relationship between a continuous feature and the label is not linear. For example, age and incomeâ€”a person's income may grow in the early stage of their career, then the growth may slow at some point, and finally, the income decreases after retirement. In this scenario, using the raw age as a real-valued feature column might not be a good choice because the model can only learn one of the three cases:\n",
        "\n",
        "* Income always increases at some rate as age grows (positive correlation),\n",
        "* Income always decreases at some rate as age grows (negative correlation), or\n",
        "* Income stays the same no matter at what age (no correlation).\n",
        "\n",
        "If we want to learn the fine-grained correlation between income and each age group separately, we can leverage **bucketization**. Bucketization is a process of dividing the entire range of a continuous feature into a set of consecutive buckets, and then converting the original numerical feature into a bucket ID (as a categorical feature) depending on which bucket that value falls into. So, we can define a **bucketized_column** over age as:"
      ]
    },
    {
      "metadata": {
        "id": "exmSA5IPNmc_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "age_buckets = tf.feature_column.bucketized_column(\n",
        "    age, boundaries=[18, 25, 30, 35, 40, 45, 50, 55, 60, 65])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ln6fLhqXNsbh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**boundaries** is a list of bucket boundaries. In this case, there are 10 boundaries, resulting in 11 age group buckets (from age 17 and below, 18-24, 25-29, ..., to 65 and over).\n",
        "\n",
        "With bucketing, the model sees each bucket a one-hot feature:"
      ]
    },
    {
      "metadata": {
        "id": "NrAS7cEQMS9w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fc.input_layer(feature_batch, [age, age_buckets]).numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-zZRyc8tOkh9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Learn complex relationships with crossed column**"
      ]
    },
    {
      "metadata": {
        "id": "t7ewLkFvOp8P",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Using each base feature column separately may not be enough to explain the data. For example, the correlation between education and the label (earning > 50,000 dollars) may be different for different occupations. Therefore, if we only learn a single model weight for education=\"Bachelors\" and education=\"Masters\", we won't capture every education-occupation combination (e.g. distinguishing between education=\"Bachelors\" AND occupation=\"Exec-managerial\" AND education=\"Bachelors\" AND occupation=\"Craft-repair\").\n",
        "\n",
        "**To learn the differences between different feature combinations, we can add crossed feature columns to the model:**"
      ]
    },
    {
      "metadata": {
        "id": "0as5l9H1OWYS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "education_x_occupation = tf.feature_column.crossed_column(\n",
        "    ['education', 'occupation'], hash_bucket_size=1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Wp-PgY7qO7Yp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can also create a **crossed_column** over more than two columns. Each constituent column can be either a base feature column that is categorical (SparseColumn), a bucketized real-valued feature column, or even another CrossColumn. For example:"
      ]
    },
    {
      "metadata": {
        "id": "kolOUEMJO5gb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "age_buckets_x_education_x_occupation = tf.feature_column.crossed_column(\n",
        "    [age_buckets, 'education', 'occupation'], hash_bucket_size=1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Mgx8WSfuPOaj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "These crossed columns always use hash buckets to avoid the exponential explosion in the number of categories, and put the control over number of model weights in the hands of the user.\n",
        "\n",
        "For a visual example the effect of hash-buckets with crossed columns see this notebook"
      ]
    },
    {
      "metadata": {
        "id": "8OheAm_jPWZx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Define the logistic regression model\n"
      ]
    },
    {
      "metadata": {
        "id": "QqD_dprsPmZD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "After processing the input data and defining all the feature columns, we can put them together and build a logistic regression model. The previous section showed several types of base and derived feature columns, including:\n",
        "\n",
        "* CategoricalColumn\n",
        "* NumericColumn\n",
        "* BucketizedColumn\n",
        "* CrossedColumn\n",
        "\n",
        "All of these are subclasses of the abstract FeatureColumn class and can be added to the feature_columns field of a model:"
      ]
    },
    {
      "metadata": {
        "id": "a-GO9sEbPTei",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "outputId": "bd791ffd-d5e0-440c-a760-2473689603e0"
      },
      "cell_type": "code",
      "source": [
        "import tempfile\n",
        "\n",
        "base_columns = [\n",
        "    education, marital_status, relationship, workclass, occupation,\n",
        "    age_buckets,\n",
        "]\n",
        "\n",
        "crossed_columns = [\n",
        "    tf.feature_column.crossed_column(\n",
        "        ['education', 'occupation'], hash_bucket_size=1000),\n",
        "    tf.feature_column.crossed_column(\n",
        "        [age_buckets, 'education', 'occupation'], hash_bucket_size=1000),\n",
        "]\n",
        "\n",
        "model = tf.estimator.LinearClassifier(\n",
        "    model_dir=tempfile.mkdtemp(), \n",
        "    feature_columns=base_columns + crossed_columns,\n",
        "    optimizer=tf.train.FtrlOptimizer(learning_rate=0.1))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0413 05:50:21.435507 140372419536768 estimator.py:1739] Using default config.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp_0697pxf', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7faac6e19a20>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0413 05:50:21.439626 140372419536768 estimator.py:201] Using config: {'_model_dir': '/tmp/tmp_0697pxf', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7faac6e19a20>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "QiunEZHBP8Rj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The model automatically learns a bias term, which controls the prediction made without observing any features. The learned model files are stored in **model_dir**."
      ]
    },
    {
      "metadata": {
        "id": "ACmXR4yWP-0x",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train and Evalulate the Model"
      ]
    },
    {
      "metadata": {
        "id": "i-1upon1QGN7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "After adding all the features to the model, let's train the model. Training a model is just a single command using the** tf.estimator** API:"
      ]
    },
    {
      "metadata": {
        "id": "QuLMbaHSPyc0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_inpf = functools.partial(census_dataset.input_fn, train_file, \n",
        "                               num_epochs=40, shuffle=True, batch_size=64)\n",
        "\n",
        "model.train(train_inpf)\n",
        "\n",
        "clear_output()  # used for notebook display\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iSyBNnMyQX8_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "After the model is trained, evaluate the accuracy of the model by predicting the labels of the holdout data:"
      ]
    },
    {
      "metadata": {
        "id": "nFy0o-QwQRmi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "outputId": "316a60d9-549d-4023-ef0e-58aeb7c71862"
      },
      "cell_type": "code",
      "source": [
        "results = model.evaluate(test_inpf)\n",
        "\n",
        "clear_output()\n",
        "\n",
        "for key,value in sorted(result.items()):\n",
        "  print('%s: %0.2f' % (key, value))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 0.85\n",
            "accuracy_baseline: 0.76\n",
            "auc: 0.90\n",
            "auc_precision_recall: 0.75\n",
            "average_loss: 0.35\n",
            "global_step: 1018.00\n",
            "label/mean: 0.24\n",
            "loss: 22.36\n",
            "precision: 0.75\n",
            "prediction/mean: 0.20\n",
            "recall: 0.54\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PwDO36lTQly-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The first line of the output should display something like: **accuracy**: 0.83, which means the accuracy is 83%. You can try using **more features and transformations** to see if you can do better!\n",
        "\n",
        "After the model is evaluated, we can use it to predict whether an individual has an annual income of over 50,000 dollars given an individual's information input.\n",
        "\n",
        "Let's look in more detail how the model performed:"
      ]
    },
    {
      "metadata": {
        "id": "9x8toxYUQwZV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1011
        },
        "outputId": "4f3276d6-fe04-4641-a426-2b35d95e9b18"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "predict_df = test_df[:20].copy()\n",
        "\n",
        "predict_df"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>workclass</th>\n",
              "      <th>fnlwgt</th>\n",
              "      <th>education</th>\n",
              "      <th>education_num</th>\n",
              "      <th>marital_status</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>gender</th>\n",
              "      <th>capital_gain</th>\n",
              "      <th>capital_loss</th>\n",
              "      <th>hours_per_week</th>\n",
              "      <th>native_country</th>\n",
              "      <th>income_bracket</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>25</td>\n",
              "      <td>Private</td>\n",
              "      <td>226802</td>\n",
              "      <td>11th</td>\n",
              "      <td>7</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Machine-op-inspct</td>\n",
              "      <td>Own-child</td>\n",
              "      <td>Black</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>38</td>\n",
              "      <td>Private</td>\n",
              "      <td>89814</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Farming-fishing</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>Local-gov</td>\n",
              "      <td>336951</td>\n",
              "      <td>Assoc-acdm</td>\n",
              "      <td>12</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Protective-serv</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&gt;50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>44</td>\n",
              "      <td>Private</td>\n",
              "      <td>160323</td>\n",
              "      <td>Some-college</td>\n",
              "      <td>10</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Machine-op-inspct</td>\n",
              "      <td>Husband</td>\n",
              "      <td>Black</td>\n",
              "      <td>Male</td>\n",
              "      <td>7688</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&gt;50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>18</td>\n",
              "      <td>?</td>\n",
              "      <td>103497</td>\n",
              "      <td>Some-college</td>\n",
              "      <td>10</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>?</td>\n",
              "      <td>Own-child</td>\n",
              "      <td>White</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>34</td>\n",
              "      <td>Private</td>\n",
              "      <td>198693</td>\n",
              "      <td>10th</td>\n",
              "      <td>6</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Other-service</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>29</td>\n",
              "      <td>?</td>\n",
              "      <td>227026</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>?</td>\n",
              "      <td>Unmarried</td>\n",
              "      <td>Black</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>63</td>\n",
              "      <td>Self-emp-not-inc</td>\n",
              "      <td>104626</td>\n",
              "      <td>Prof-school</td>\n",
              "      <td>15</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>3103</td>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&gt;50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>24</td>\n",
              "      <td>Private</td>\n",
              "      <td>369667</td>\n",
              "      <td>Some-college</td>\n",
              "      <td>10</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Other-service</td>\n",
              "      <td>Unmarried</td>\n",
              "      <td>White</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>55</td>\n",
              "      <td>Private</td>\n",
              "      <td>104996</td>\n",
              "      <td>7th-8th</td>\n",
              "      <td>4</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Craft-repair</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>65</td>\n",
              "      <td>Private</td>\n",
              "      <td>184454</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Machine-op-inspct</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>6418</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&gt;50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>36</td>\n",
              "      <td>Federal-gov</td>\n",
              "      <td>212465</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Adm-clerical</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>26</td>\n",
              "      <td>Private</td>\n",
              "      <td>82091</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Adm-clerical</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>39</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>58</td>\n",
              "      <td>?</td>\n",
              "      <td>299831</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>?</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>48</td>\n",
              "      <td>Private</td>\n",
              "      <td>279724</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Machine-op-inspct</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>3103</td>\n",
              "      <td>0</td>\n",
              "      <td>48</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&gt;50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>43</td>\n",
              "      <td>Private</td>\n",
              "      <td>346189</td>\n",
              "      <td>Masters</td>\n",
              "      <td>14</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Exec-managerial</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&gt;50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>20</td>\n",
              "      <td>State-gov</td>\n",
              "      <td>444554</td>\n",
              "      <td>Some-college</td>\n",
              "      <td>10</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Other-service</td>\n",
              "      <td>Own-child</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>25</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>43</td>\n",
              "      <td>Private</td>\n",
              "      <td>128354</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Adm-clerical</td>\n",
              "      <td>Wife</td>\n",
              "      <td>White</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>37</td>\n",
              "      <td>Private</td>\n",
              "      <td>60548</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Widowed</td>\n",
              "      <td>Machine-op-inspct</td>\n",
              "      <td>Unmarried</td>\n",
              "      <td>White</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>40</td>\n",
              "      <td>Private</td>\n",
              "      <td>85019</td>\n",
              "      <td>Doctorate</td>\n",
              "      <td>16</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>Husband</td>\n",
              "      <td>Asian-Pac-Islander</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>45</td>\n",
              "      <td>?</td>\n",
              "      <td>&gt;50K</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    age         workclass  fnlwgt     education  education_num  \\\n",
              "0    25           Private  226802          11th              7   \n",
              "1    38           Private   89814       HS-grad              9   \n",
              "2    28         Local-gov  336951    Assoc-acdm             12   \n",
              "3    44           Private  160323  Some-college             10   \n",
              "4    18                 ?  103497  Some-college             10   \n",
              "5    34           Private  198693          10th              6   \n",
              "6    29                 ?  227026       HS-grad              9   \n",
              "7    63  Self-emp-not-inc  104626   Prof-school             15   \n",
              "8    24           Private  369667  Some-college             10   \n",
              "9    55           Private  104996       7th-8th              4   \n",
              "10   65           Private  184454       HS-grad              9   \n",
              "11   36       Federal-gov  212465     Bachelors             13   \n",
              "12   26           Private   82091       HS-grad              9   \n",
              "13   58                 ?  299831       HS-grad              9   \n",
              "14   48           Private  279724       HS-grad              9   \n",
              "15   43           Private  346189       Masters             14   \n",
              "16   20         State-gov  444554  Some-college             10   \n",
              "17   43           Private  128354       HS-grad              9   \n",
              "18   37           Private   60548       HS-grad              9   \n",
              "19   40           Private   85019     Doctorate             16   \n",
              "\n",
              "        marital_status         occupation   relationship                race  \\\n",
              "0        Never-married  Machine-op-inspct      Own-child               Black   \n",
              "1   Married-civ-spouse    Farming-fishing        Husband               White   \n",
              "2   Married-civ-spouse    Protective-serv        Husband               White   \n",
              "3   Married-civ-spouse  Machine-op-inspct        Husband               Black   \n",
              "4        Never-married                  ?      Own-child               White   \n",
              "5        Never-married      Other-service  Not-in-family               White   \n",
              "6        Never-married                  ?      Unmarried               Black   \n",
              "7   Married-civ-spouse     Prof-specialty        Husband               White   \n",
              "8        Never-married      Other-service      Unmarried               White   \n",
              "9   Married-civ-spouse       Craft-repair        Husband               White   \n",
              "10  Married-civ-spouse  Machine-op-inspct        Husband               White   \n",
              "11  Married-civ-spouse       Adm-clerical        Husband               White   \n",
              "12       Never-married       Adm-clerical  Not-in-family               White   \n",
              "13  Married-civ-spouse                  ?        Husband               White   \n",
              "14  Married-civ-spouse  Machine-op-inspct        Husband               White   \n",
              "15  Married-civ-spouse    Exec-managerial        Husband               White   \n",
              "16       Never-married      Other-service      Own-child               White   \n",
              "17  Married-civ-spouse       Adm-clerical           Wife               White   \n",
              "18             Widowed  Machine-op-inspct      Unmarried               White   \n",
              "19  Married-civ-spouse     Prof-specialty        Husband  Asian-Pac-Islander   \n",
              "\n",
              "    gender  capital_gain  capital_loss  hours_per_week native_country  \\\n",
              "0     Male             0             0              40  United-States   \n",
              "1     Male             0             0              50  United-States   \n",
              "2     Male             0             0              40  United-States   \n",
              "3     Male          7688             0              40  United-States   \n",
              "4   Female             0             0              30  United-States   \n",
              "5     Male             0             0              30  United-States   \n",
              "6     Male             0             0              40  United-States   \n",
              "7     Male          3103             0              32  United-States   \n",
              "8   Female             0             0              40  United-States   \n",
              "9     Male             0             0              10  United-States   \n",
              "10    Male          6418             0              40  United-States   \n",
              "11    Male             0             0              40  United-States   \n",
              "12  Female             0             0              39  United-States   \n",
              "13    Male             0             0              35  United-States   \n",
              "14    Male          3103             0              48  United-States   \n",
              "15    Male             0             0              50  United-States   \n",
              "16    Male             0             0              25  United-States   \n",
              "17  Female             0             0              30  United-States   \n",
              "18  Female             0             0              20  United-States   \n",
              "19    Male             0             0              45              ?   \n",
              "\n",
              "   income_bracket  \n",
              "0           <=50K  \n",
              "1           <=50K  \n",
              "2            >50K  \n",
              "3            >50K  \n",
              "4           <=50K  \n",
              "5           <=50K  \n",
              "6           <=50K  \n",
              "7            >50K  \n",
              "8           <=50K  \n",
              "9           <=50K  \n",
              "10           >50K  \n",
              "11          <=50K  \n",
              "12          <=50K  \n",
              "13          <=50K  \n",
              "14           >50K  \n",
              "15           >50K  \n",
              "16          <=50K  \n",
              "17          <=50K  \n",
              "18          <=50K  \n",
              "19           >50K  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "metadata": {
        "id": "8rl8w6rWRNn5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "777b6e1f-2e4f-4603-bf68-91fe53a0fd1c"
      },
      "cell_type": "code",
      "source": [
        "pred_iter = model.predict(\n",
        "    lambda:easy_input_function(predict_df, label_key='income_bracket',\n",
        "                               num_epochs=1, shuffle=False, batch_size=10))\n",
        "\n",
        "pred_iter"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<generator object EstimatorV2.predict at 0x7faac4635af0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "metadata": {
        "id": "jYpPo6acRThK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f0a10c19-0b7e-4738-e9ed-e015f09474aa"
      },
      "cell_type": "code",
      "source": [
        "classes = np.array(['<=50K', '>50K'])\n",
        "pred_class_id = []\n",
        "classes"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['<=50K', '>50K'], dtype='<U5')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "metadata": {
        "id": "SsdMw_L1RZeY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        },
        "outputId": "20267637-eb9a-4967-8ecf-d5266bcfd5aa"
      },
      "cell_type": "code",
      "source": [
        "for pred_dict in pred_iter:\n",
        "  pred_class_id.append(pred_dict['class_ids'])\n",
        "  \n",
        "pred_class_id"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0413 05:57:50.014869 140372419536768 estimator.py:1111] Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0413 05:57:51.062300 140372419536768 estimator.py:1113] Done calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0413 05:57:51.209964 140372419536768 monitored_session.py:222] Graph was finalized.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /tmp/tmp_0697pxf/model.ckpt-20351\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0413 05:57:51.219778 140372419536768 saver.py:1270] Restoring parameters from /tmp/tmp_0697pxf/model.ckpt-20351\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0413 05:57:51.310737 140372419536768 session_manager.py:491] Running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0413 05:57:51.343444 140372419536768 session_manager.py:493] Done running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([0]),\n",
              " array([0]),\n",
              " array([0]),\n",
              " array([0]),\n",
              " array([0]),\n",
              " array([0]),\n",
              " array([0]),\n",
              " array([1]),\n",
              " array([0]),\n",
              " array([0]),\n",
              " array([0]),\n",
              " array([1]),\n",
              " array([0]),\n",
              " array([0]),\n",
              " array([0]),\n",
              " array([1]),\n",
              " array([0]),\n",
              " array([0]),\n",
              " array([0]),\n",
              " array([1])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "metadata": {
        "id": "57eoTLGDRxCV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 667
        },
        "outputId": "4e8a8e1e-5573-4859-fb87-408b413e0b9a"
      },
      "cell_type": "code",
      "source": [
        "predict_df['predicted_class'] = classes[np.array(pred_class_id)]\n",
        "predict_df['correct'] = predict_df['predicted_class'] == predict_df['income_bracket']\n",
        "\n",
        "clear_output()\n",
        "\n",
        "predict_df[['income_bracket','predicted_class', 'correct']]"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>income_bracket</th>\n",
              "      <th>predicted_class</th>\n",
              "      <th>correct</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;=50K</td>\n",
              "      <td>&lt;=50K</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>&lt;=50K</td>\n",
              "      <td>&lt;=50K</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>&gt;50K</td>\n",
              "      <td>&lt;=50K</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>&gt;50K</td>\n",
              "      <td>&lt;=50K</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>&lt;=50K</td>\n",
              "      <td>&lt;=50K</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>&lt;=50K</td>\n",
              "      <td>&lt;=50K</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>&lt;=50K</td>\n",
              "      <td>&lt;=50K</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>&gt;50K</td>\n",
              "      <td>&gt;50K</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>&lt;=50K</td>\n",
              "      <td>&lt;=50K</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>&lt;=50K</td>\n",
              "      <td>&lt;=50K</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>&gt;50K</td>\n",
              "      <td>&lt;=50K</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>&lt;=50K</td>\n",
              "      <td>&gt;50K</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>&lt;=50K</td>\n",
              "      <td>&lt;=50K</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>&lt;=50K</td>\n",
              "      <td>&lt;=50K</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>&gt;50K</td>\n",
              "      <td>&lt;=50K</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>&gt;50K</td>\n",
              "      <td>&gt;50K</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>&lt;=50K</td>\n",
              "      <td>&lt;=50K</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>&lt;=50K</td>\n",
              "      <td>&lt;=50K</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>&lt;=50K</td>\n",
              "      <td>&lt;=50K</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>&gt;50K</td>\n",
              "      <td>&gt;50K</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   income_bracket predicted_class  correct\n",
              "0           <=50K           <=50K     True\n",
              "1           <=50K           <=50K     True\n",
              "2            >50K           <=50K    False\n",
              "3            >50K           <=50K    False\n",
              "4           <=50K           <=50K     True\n",
              "5           <=50K           <=50K     True\n",
              "6           <=50K           <=50K     True\n",
              "7            >50K            >50K     True\n",
              "8           <=50K           <=50K     True\n",
              "9           <=50K           <=50K     True\n",
              "10           >50K           <=50K    False\n",
              "11          <=50K            >50K    False\n",
              "12          <=50K           <=50K     True\n",
              "13          <=50K           <=50K     True\n",
              "14           >50K           <=50K    False\n",
              "15           >50K            >50K     True\n",
              "16          <=50K           <=50K     True\n",
              "17          <=50K           <=50K     True\n",
              "18          <=50K           <=50K     True\n",
              "19           >50K            >50K     True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "metadata": {
        "id": "-pZC5n-nSGEg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Adding Regularization to Prevent Overfitting"
      ]
    },
    {
      "metadata": {
        "id": "DtXE7k33SGKy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Regularization is a technique used to avoid overfitting. Overfitting happens when a model performs well on the data it is trained on, but worse on test data that the model has not seen before. Overfitting can occur when a model is excessively complex, such as having too many parameters relative to the number of observed training data. Regularization allows you to control the model's complexity and make the model more generalizable to unseen data.\n",
        "\n",
        "You can add L1 and L2 regularizations to the model with the following code:"
      ]
    },
    {
      "metadata": {
        "id": "Nrmtv2gPR_X-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "outputId": "b81f9567-c714-4a45-92a5-dae2e81cd7d4"
      },
      "cell_type": "code",
      "source": [
        "model_l1 = tf.estimator.LinearClassifier(\n",
        "    feature_columns=base_columns + crossed_columns,\n",
        "    optimizer=tf.train.FtrlOptimizer(\n",
        "        learning_rate=0.1,\n",
        "        l1_regularization_strength=10.0,\n",
        "        l2_regularization_strength=0.0))\n",
        "\n",
        "model_l1.train(train_inpf)\n",
        "\n",
        "results = model_l1.evaluate(test_inpf)\n",
        "clear_output()\n",
        "for key in sorted(results):\n",
        "  print('%s: %0.2f' % (key, results[key]))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 0.84\n",
            "accuracy_baseline: 0.76\n",
            "auc: 0.88\n",
            "auc_precision_recall: 0.69\n",
            "average_loss: 0.35\n",
            "global_step: 20351.00\n",
            "label/mean: 0.24\n",
            "loss: 22.47\n",
            "precision: 0.69\n",
            "prediction/mean: 0.24\n",
            "recall: 0.55\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XyGSh_HASM_2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "outputId": "53240082-6911-48df-b02a-6a768121b202"
      },
      "cell_type": "code",
      "source": [
        "model_l2 = tf.estimator.LinearClassifier(\n",
        "    feature_columns=base_columns + crossed_columns,\n",
        "    optimizer=tf.train.FtrlOptimizer(\n",
        "        learning_rate=0.1,\n",
        "        l1_regularization_strength=0.0,\n",
        "        l2_regularization_strength=10.0))\n",
        "\n",
        "model_l2.train(train_inpf)\n",
        "\n",
        "results = model_l2.evaluate(test_inpf)\n",
        "clear_output()\n",
        "for key in sorted(results):\n",
        "  print('%s: %0.2f' % (key, results[key]))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 0.84\n",
            "accuracy_baseline: 0.76\n",
            "auc: 0.88\n",
            "auc_precision_recall: 0.69\n",
            "average_loss: 0.35\n",
            "global_step: 20351.00\n",
            "label/mean: 0.24\n",
            "loss: 22.47\n",
            "precision: 0.69\n",
            "prediction/mean: 0.23\n",
            "recall: 0.54\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XgB6E88jTYj7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "These regularized models don't perform much better than the base model. Let's look at the model's weight distributions to better see the effect of the regularization:"
      ]
    },
    {
      "metadata": {
        "id": "2keoIDFITd9p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_flat_weights(model):\n",
        "  weight_names = [\n",
        "      name for name in model.get_variable_names()\n",
        "      if \"linear_model\" in name and \"Ftrl\" not in name]\n",
        "\n",
        "  weight_values = [model.get_variable_value(name) for name in weight_names]\n",
        "\n",
        "  weights_flat = np.concatenate([item.flatten() for item in weight_values], axis=0)\n",
        "\n",
        "  return weights_flat\n",
        "\n",
        "weights_flat = get_flat_weights(model)\n",
        "weights_flat_l1 = get_flat_weights(model_l1)\n",
        "weights_flat_l2 = get_flat_weights(model_l2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Nrz523kTUIrc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The models have many zero-valued weights caused by unused hash bins (there are many more hash bins than categories in some columns). We can mask these weights when viewing the weight distributions:"
      ]
    },
    {
      "metadata": {
        "id": "x8H4itk7UNb_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "weight_mask = weights_flat != 0\n",
        "\n",
        "weights_base = weights_flat[weight_mask]\n",
        "weights_l1 = weights_flat_l1[weight_mask]\n",
        "weights_l2 = weights_flat_l2[weight_mask]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gflCz98-UhsK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 809
        },
        "outputId": "2fa1a106-de4a-4437-cc17-388ead60b52a"
      },
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "_ = plt.hist(weights_base, bins=np.linspace(-3,3,30))\n",
        "plt.title('Base Model')\n",
        "plt.ylim([0,500])\n",
        "\n",
        "plt.figure()\n",
        "_ = plt.hist(weights_l1, bins=np.linspace(-3,3,30))\n",
        "plt.title('L1 - Regularization')\n",
        "plt.ylim([0,500])\n",
        "\n",
        "plt.figure()\n",
        "_ = plt.hist(weights_l2, bins=np.linspace(-3,3,30))\n",
        "plt.title('L2 - Regularization')\n",
        "_=plt.ylim([0,500])"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nl6TO/R8r4QVB64iJDwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGfSS1Ln/BUFMUbgBErkFAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "9bQKUsjtUt6s",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Both types of regularization squeeze the distribution of weights towards zero. \n",
        "* L2 regularization has a greater effect in the tails of the distribution eliminating extreme weights. \n",
        "* L1 regularization produces more exactly-zero values, in this case it sets ~200 to zero."
      ]
    },
    {
      "metadata": {
        "id": "S2aa99qPUkE1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}